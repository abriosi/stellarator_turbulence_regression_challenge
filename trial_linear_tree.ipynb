{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import shap\n",
    "import pickle\n",
    "import optuna\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna.integration\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "SEED = 1338\n",
    "\n",
    "# File with the flux tube geometries (features):\n",
    "in_filename = \"20240601-01-assembleFluxTubeMatrix_normalizeMeanStdIndependentOfZ_withAndWithoutCvdrift_nz97_withCvdrift.pkl\"\n",
    "# File with the GX heat flux\n",
    "out_filename = \"20240601-01-103_gx_nfp4_production_gx_results.pkl\"\n",
    "\n",
    "with open(in_filename, \"rb\") as f:\n",
    "    in_data = pickle.load(f)\n",
    "\n",
    "with open(out_filename, \"rb\") as f:\n",
    "    out_data = pickle.load(f)\n",
    "\n",
    "X = in_data[\"matrix\"]\n",
    "heat_flux_averages = out_data[\"Q_avgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tube_files', 'nl', 'z_functions', 'scalars', 'n_features', 'n_quantities', 'n_tubes', 'matrix', 'means', 'standard_deviations'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02278433,  0.79329694,  0.47829241, ..., -0.85963928,\n",
       "        -0.8744202 , -0.80227028],\n",
       "       [ 1.87583922,  1.81435098,  0.96975006, ...,  0.95706323,\n",
       "         0.87230722,  0.27335504],\n",
       "       [ 0.43586769,  1.80462561,  1.59276536, ..., -0.4965529 ,\n",
       "        -0.77648957, -0.89956508],\n",
       "       ...,\n",
       "       [ 0.13053565, -0.7773523 , -0.59668751, ..., -0.37490712,\n",
       "        -0.62196128, -0.69224254],\n",
       "       [-1.35382024, -0.85957927, -0.1629058 , ...,  2.14119896,\n",
       "         2.06968399,  1.78776422],\n",
       "       [-0.31146954, -0.13072943, -0.79157277, ...,  1.37519525,\n",
       "         1.23457818,  0.48518993]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data[\"matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.75939  ,  9.549901 , 11.110395 , ..., 16.632994 ,  7.2723794,\n",
       "       16.234438 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data[\"Q_avgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = in_data[\"matrix\"]\n",
    "target = np.log(out_data[\"Q_avgs\"])\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(features, target, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 14:20:09,527] A new study created in memory with name: no-name-8253d320-947f-441a-aee0-7e6645c23ec2\n",
      "[I 2024-06-13 14:20:17,944] Trial 0 finished with value: 3.0651473363647908 and parameters: {'objective': 'regression_l1', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.13301648951575726, 'lambda_l2': 0.0465439550799397, 'num_leaves': 280, 'feature_fraction': 0.20093617600437247, 'bagging_fraction': 0.1375258026425314, 'bagging_freq': 8, 'min_child_samples': 10, 'learning_rate': 1.3732916339377326e-05, 'max_depth': -1, 'min_split_gain': 0.48107219848487204, 'subsample': 0.8511670810894018, 'colsample_bytree': 0.2176504192291312, 'num_iterations': 620, 'max_bin': 703, 'seed': 1338}. Best is trial 0 with value: 3.0651473363647908.\n",
      "[I 2024-06-13 14:20:18,930] Trial 1 finished with value: 4.280653427288993 and parameters: {'objective': 'regression_l1', 'boosting_type': 'dart', 'linear_tree': False, 'lambda_l1': 6.577034248096407e-08, 'lambda_l2': 4.475195467231305e-08, 'num_leaves': 18, 'feature_fraction': 0.5167971277486508, 'bagging_fraction': 0.8996065278798359, 'bagging_freq': 2, 'min_child_samples': 66, 'learning_rate': 0.0005516449511547554, 'max_depth': 48, 'min_split_gain': 0.46734929668621383, 'subsample': 0.7085763509438385, 'colsample_bytree': 0.7520257524813955, 'num_iterations': 142, 'max_bin': 407, 'seed': 1338}. Best is trial 0 with value: 3.0651473363647908.\n",
      "[I 2024-06-13 14:20:21,656] Trial 2 finished with value: -0.694527397371922 and parameters: {'objective': 'regression_l1', 'boosting_type': 'gbdt', 'linear_tree': False, 'lambda_l1': 0.010548500183788338, 'lambda_l2': 1.1359857249721322e-06, 'num_leaves': 137, 'feature_fraction': 0.5451977777003383, 'bagging_fraction': 0.21729557198030816, 'bagging_freq': 5, 'min_child_samples': 65, 'learning_rate': 0.09583013361630309, 'max_depth': 36, 'min_split_gain': 0.6469527482837966, 'subsample': 0.40903161786456443, 'colsample_bytree': 0.46255867864960987, 'num_iterations': 614, 'max_bin': 180, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:20:24,977] Trial 3 finished with value: -0.008024800584960246 and parameters: {'objective': 'regression_l2', 'boosting_type': 'gbdt', 'linear_tree': True, 'lambda_l1': 0.008320948557084961, 'lambda_l2': 3.144029280811219e-07, 'num_leaves': 47, 'feature_fraction': 0.7133352517998055, 'bagging_fraction': 0.5105025539899498, 'bagging_freq': 1, 'min_child_samples': 57, 'learning_rate': 4.132258122273982e-05, 'max_depth': 2, 'min_split_gain': 0.8212337404950313, 'subsample': 0.3201922136650839, 'colsample_bytree': 0.5576896907604809, 'num_iterations': 752, 'max_bin': 971, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:21:02,158] Trial 4 finished with value: 297423.1334426481 and parameters: {'objective': 'regression_l1', 'boosting_type': 'gbdt', 'linear_tree': True, 'lambda_l1': 0.41261215954607416, 'lambda_l2': 0.08071954158249775, 'num_leaves': 416, 'feature_fraction': 0.8411499565063427, 'bagging_fraction': 0.7396157675307382, 'bagging_freq': 1, 'min_child_samples': 14, 'learning_rate': 0.010540116202221738, 'max_depth': 29, 'min_split_gain': 0.9078579677836446, 'subsample': 0.3265682678867793, 'colsample_bytree': 0.2908836151434091, 'num_iterations': 283, 'max_bin': 752, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:21:02,666] Trial 5 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:21:03,080] Trial 6 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:21:03,769] Trial 7 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:22:47,897] Trial 8 finished with value: -0.3794107923851824 and parameters: {'objective': 'regression_l1', 'boosting_type': 'rf', 'linear_tree': False, 'lambda_l1': 5.58445088269097e-05, 'lambda_l2': 1.0181413009798166e-07, 'num_leaves': 169, 'feature_fraction': 0.8517353965265971, 'bagging_fraction': 0.5623867377926535, 'bagging_freq': 6, 'min_child_samples': 7, 'learning_rate': 0.006391914649515211, 'max_depth': 11, 'min_split_gain': 0.8619498639259022, 'subsample': 0.6442300990661373, 'colsample_bytree': 0.6665893946002287, 'num_iterations': 966, 'max_bin': 914, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:23:14,788] Trial 9 finished with value: -0.5248563828435738 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': False, 'lambda_l1': 1.5108803513111344, 'lambda_l2': 4.541276598391471, 'num_leaves': 161, 'feature_fraction': 0.7065434653617804, 'bagging_fraction': 0.6030527306832733, 'bagging_freq': 9, 'min_child_samples': 35, 'learning_rate': 0.005363732238689724, 'max_depth': 49, 'min_split_gain': 0.004471356431080986, 'subsample': 0.3577266195189466, 'colsample_bytree': 0.6417367751969919, 'num_iterations': 712, 'max_bin': 760, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:23:14,964] Trial 10 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:23:16,604] Trial 11 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:23:16,878] Trial 12 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:23:17,195] Trial 13 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:23:17,599] Trial 14 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:23:17,908] Trial 15 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:23:18,221] Trial 16 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:23:18,436] Trial 17 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:23:18,873] Trial 18 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:23:19,207] Trial 19 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:23:19,853] Trial 20 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:23:20,548] Trial 21 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:23:21,045] Trial 22 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:26:55,763] Trial 23 finished with value: -0.3934933878576786 and parameters: {'objective': 'regression_l1', 'boosting_type': 'rf', 'linear_tree': False, 'lambda_l1': 6.118189438969711e-06, 'lambda_l2': 1.2890313378423992e-08, 'num_leaves': 242, 'feature_fraction': 0.9284747356753553, 'bagging_fraction': 0.7536228899480535, 'bagging_freq': 9, 'min_child_samples': 3, 'learning_rate': 0.030475075797126418, 'max_depth': 16, 'min_split_gain': 0.8015888310385704, 'subsample': 0.3539992528134276, 'colsample_bytree': 0.5149906204656286, 'num_iterations': 1000, 'max_bin': 642, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:26:56,132] Trial 24 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:26:56,519] Trial 25 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:03,378] Trial 26 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:27:03,678] Trial 27 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:27:03,995] Trial 28 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:04,822] Trial 29 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:27:05,450] Trial 30 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:27:05,965] Trial 31 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:06,263] Trial 32 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:06,582] Trial 33 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:06,996] Trial 34 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:07,595] Trial 35 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:27:07,837] Trial 36 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:36,411] Trial 37 finished with value: -0.5673642432614678 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.24978890132916426, 'lambda_l2': 9.082029469742158e-07, 'num_leaves': 215, 'feature_fraction': 0.8346426573151016, 'bagging_fraction': 0.5219448839464634, 'bagging_freq': 10, 'min_child_samples': 51, 'learning_rate': 0.01732913165231727, 'max_depth': 26, 'min_split_gain': 0.5268648791498719, 'subsample': 0.5422146389854756, 'colsample_bytree': 0.28011542038481085, 'num_iterations': 940, 'max_bin': 753, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:27:36,907] Trial 38 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:27:37,444] Trial 39 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:27:38,414] Trial 40 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:27:50,554] Trial 41 finished with value: -0.46974869737475244 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 9.32563890622645, 'lambda_l2': 8.450064049813149e-07, 'num_leaves': 173, 'feature_fraction': 0.8708076147751732, 'bagging_fraction': 0.6072835261126178, 'bagging_freq': 9, 'min_child_samples': 73, 'learning_rate': 0.017756204254419605, 'max_depth': 5, 'min_split_gain': 0.6691617460458665, 'subsample': 0.606742562142674, 'colsample_bytree': 0.3005700424464797, 'num_iterations': 956, 'max_bin': 812, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:28:13,807] Trial 42 finished with value: -0.5448814600103754 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 9.566667930102936, 'lambda_l2': 8.463271183885974e-07, 'num_leaves': 204, 'feature_fraction': 0.9590671677343791, 'bagging_fraction': 0.697354832263703, 'bagging_freq': 9, 'min_child_samples': 74, 'learning_rate': 0.015838605751663525, 'max_depth': 28, 'min_split_gain': 0.6852996099602526, 'subsample': 0.6008270584558218, 'colsample_bytree': 0.29952975593764347, 'num_iterations': 1000, 'max_bin': 804, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:28:14,142] Trial 43 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:15,995] Trial 44 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:28:16,747] Trial 45 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:28:17,139] Trial 46 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:27,151] Trial 47 finished with value: -0.6632636533528125 and parameters: {'objective': 'regression_l2', 'boosting_type': 'gbdt', 'linear_tree': True, 'lambda_l1': 9.66890711563121, 'lambda_l2': 3.6001688447046485e-07, 'num_leaves': 89, 'feature_fraction': 0.9466204555493732, 'bagging_fraction': 0.6126633489263472, 'bagging_freq': 10, 'min_child_samples': 54, 'learning_rate': 0.0031211193284127613, 'max_depth': 22, 'min_split_gain': 0.699248685182469, 'subsample': 0.4202071318942628, 'colsample_bytree': 0.41354960627491394, 'num_iterations': 869, 'max_bin': 166, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:28:27,396] Trial 48 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:27,629] Trial 49 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:27,889] Trial 50 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:28,159] Trial 51 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:28:28,498] Trial 52 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:28:28,975] Trial 53 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:29,354] Trial 54 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:29,914] Trial 55 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:28:30,161] Trial 56 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:28:30,490] Trial 57 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:31,057] Trial 58 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:28:31,499] Trial 59 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:31,810] Trial 60 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:32,828] Trial 61 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:28:33,269] Trial 62 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:28:33,989] Trial 63 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:28:34,313] Trial 64 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:29:03,350] Trial 65 finished with value: -0.6281822632478864 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.660907388977914e-08, 'lambda_l2': 2.6392418846535868e-08, 'num_leaves': 264, 'feature_fraction': 0.5086776511631877, 'bagging_fraction': 0.7550601673099941, 'bagging_freq': 9, 'min_child_samples': 46, 'learning_rate': 0.06823142273259881, 'max_depth': 23, 'min_split_gain': 0.0036378364501630234, 'subsample': 0.6527893430617422, 'colsample_bytree': 0.578793772523788, 'num_iterations': 523, 'max_bin': 860, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:29:04,475] Trial 66 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:29:05,228] Trial 67 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:29:32,659] Trial 68 finished with value: -0.6636868203971724 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.0960697949393405, 'lambda_l2': 0.00563575963127096, 'num_leaves': 205, 'feature_fraction': 0.4285001686425524, 'bagging_fraction': 0.7958019271032454, 'bagging_freq': 7, 'min_child_samples': 35, 'learning_rate': 0.19875818944481718, 'max_depth': 29, 'min_split_gain': 0.1260413440575257, 'subsample': 0.7958892770773103, 'colsample_bytree': 0.7033968271190231, 'num_iterations': 447, 'max_bin': 926, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:30:07,049] Trial 69 finished with value: -0.6830670020219693 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.7558298849793956, 'lambda_l2': 2.08779558248319, 'num_leaves': 263, 'feature_fraction': 0.41681765036124574, 'bagging_fraction': 0.7845206632468964, 'bagging_freq': 7, 'min_child_samples': 28, 'learning_rate': 0.9630517769381522, 'max_depth': 29, 'min_split_gain': 0.1454392411664166, 'subsample': 0.8668022628090286, 'colsample_bytree': 0.7117100551404062, 'num_iterations': 485, 'max_bin': 985, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:30:33,695] Trial 70 finished with value: -0.6903462047502195 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0561522603305238, 'lambda_l2': 0.006285318979377748, 'num_leaves': 309, 'feature_fraction': 0.30782946044577403, 'bagging_fraction': 0.8040340202431735, 'bagging_freq': 7, 'min_child_samples': 29, 'learning_rate': 0.8508191489976422, 'max_depth': 29, 'min_split_gain': 0.14741649518167643, 'subsample': 0.8944139484509892, 'colsample_bytree': 0.8637315212547713, 'num_iterations': 350, 'max_bin': 989, 'seed': 1338}. Best is trial 2 with value: -0.694527397371922.\n",
      "[I 2024-06-13 14:30:59,968] Trial 71 finished with value: -0.6976700636333262 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.03799020350769852, 'lambda_l2': 0.007773856184251813, 'num_leaves': 329, 'feature_fraction': 0.26348293296904246, 'bagging_fraction': 0.8665902930415401, 'bagging_freq': 7, 'min_child_samples': 29, 'learning_rate': 0.984146520646394, 'max_depth': 29, 'min_split_gain': 0.14011726132142865, 'subsample': 0.8708838654726067, 'colsample_bytree': 0.8624458115568162, 'num_iterations': 350, 'max_bin': 975, 'seed': 1338}. Best is trial 71 with value: -0.6976700636333262.\n",
      "[I 2024-06-13 14:31:28,948] Trial 72 finished with value: -0.7005153368417327 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.04614307174123441, 'lambda_l2': 0.006383715230849046, 'num_leaves': 318, 'feature_fraction': 0.2762186829649318, 'bagging_fraction': 0.8578789982194971, 'bagging_freq': 7, 'min_child_samples': 27, 'learning_rate': 0.9731499558835902, 'max_depth': 30, 'min_split_gain': 0.14727874216123008, 'subsample': 0.8978771627944688, 'colsample_bytree': 0.8881441630274738, 'num_iterations': 332, 'max_bin': 988, 'seed': 1338}. Best is trial 72 with value: -0.7005153368417327.\n",
      "[I 2024-06-13 14:31:57,791] Trial 73 finished with value: -0.6963619237202768 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.008691307572503188, 'lambda_l2': 0.004718890084693972, 'num_leaves': 319, 'feature_fraction': 0.26535013143262276, 'bagging_fraction': 0.8630218739125968, 'bagging_freq': 7, 'min_child_samples': 29, 'learning_rate': 0.949983592365241, 'max_depth': 30, 'min_split_gain': 0.14063542666070922, 'subsample': 0.8740389626308984, 'colsample_bytree': 0.9034701667994665, 'num_iterations': 348, 'max_bin': 987, 'seed': 1338}. Best is trial 72 with value: -0.7005153368417327.\n",
      "[I 2024-06-13 14:31:59,098] Trial 74 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:32:26,249] Trial 75 finished with value: -0.6989637983191541 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.03686185987641638, 'lambda_l2': 0.023884203713647644, 'num_leaves': 360, 'feature_fraction': 0.18723426299976992, 'bagging_fraction': 0.8701839373383328, 'bagging_freq': 7, 'min_child_samples': 30, 'learning_rate': 0.6132498183315407, 'max_depth': 33, 'min_split_gain': 0.1679318369790619, 'subsample': 0.8773665005847282, 'colsample_bytree': 0.8849951983798442, 'num_iterations': 379, 'max_bin': 981, 'seed': 1338}. Best is trial 72 with value: -0.7005153368417327.\n",
      "[I 2024-06-13 14:32:52,135] Trial 76 finished with value: -0.706074646910166 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.05129760704630585, 'lambda_l2': 0.02149386896068722, 'num_leaves': 396, 'feature_fraction': 0.16263238386772227, 'bagging_fraction': 0.8636933475492653, 'bagging_freq': 7, 'min_child_samples': 28, 'learning_rate': 0.6844615698460789, 'max_depth': 32, 'min_split_gain': 0.17627322395842124, 'subsample': 0.8795145887686013, 'colsample_bytree': 0.8916413942256549, 'num_iterations': 361, 'max_bin': 989, 'seed': 1338}. Best is trial 76 with value: -0.706074646910166.\n",
      "[I 2024-06-13 14:33:22,581] Trial 77 finished with value: -0.7139088578977058 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.049451702256769516, 'lambda_l2': 0.03639381788083874, 'num_leaves': 401, 'feature_fraction': 0.158271159293565, 'bagging_fraction': 0.8789019205354097, 'bagging_freq': 6, 'min_child_samples': 24, 'learning_rate': 0.7583837005141676, 'max_depth': 32, 'min_split_gain': 0.21362656854767992, 'subsample': 0.8935718708976511, 'colsample_bytree': 0.880185172142843, 'num_iterations': 357, 'max_bin': 993, 'seed': 1338}. Best is trial 77 with value: -0.7139088578977058.\n",
      "[I 2024-06-13 14:33:24,020] Trial 78 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:33:25,521] Trial 79 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:33:55,097] Trial 80 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:33:58,794] Trial 81 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:34:15,863] Trial 82 finished with value: -0.7020433913258239 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0033695237880332616, 'lambda_l2': 0.02933346161869537, 'num_leaves': 311, 'feature_fraction': 0.1681609707344698, 'bagging_fraction': 0.8786547705844566, 'bagging_freq': 7, 'min_child_samples': 30, 'learning_rate': 0.8147643423326216, 'max_depth': 35, 'min_split_gain': 0.23808884794895985, 'subsample': 0.8632330785930596, 'colsample_bytree': 0.9219905763302905, 'num_iterations': 238, 'max_bin': 966, 'seed': 1338}. Best is trial 77 with value: -0.7139088578977058.\n",
      "[I 2024-06-13 14:34:17,976] Trial 83 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:34:19,633] Trial 84 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:34:23,117] Trial 85 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:34:24,001] Trial 86 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:34:25,017] Trial 87 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:34:26,379] Trial 88 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:34:27,027] Trial 89 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:34:28,194] Trial 90 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:34:31,299] Trial 91 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:34:33,685] Trial 92 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:34:47,934] Trial 93 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:35:38,961] Trial 94 finished with value: -0.7224108043167705 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0019160104874625067, 'lambda_l2': 1.248518872356049, 'num_leaves': 343, 'feature_fraction': 0.24275428334818716, 'bagging_fraction': 0.9505890053481898, 'bagging_freq': 7, 'min_child_samples': 21, 'learning_rate': 0.6152240514671602, 'max_depth': 28, 'min_split_gain': 0.3246627172509914, 'subsample': 0.8685346536513153, 'colsample_bytree': 0.8839794810705041, 'num_iterations': 491, 'max_bin': 1023, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:35:40,499] Trial 95 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:35:42,829] Trial 96 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:35:43,961] Trial 97 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:35:49,620] Trial 98 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:35:50,527] Trial 99 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:35:53,431] Trial 100 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:35:54,618] Trial 101 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:35:55,386] Trial 102 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:35:56,269] Trial 103 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:36:06,611] Trial 104 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:36:09,045] Trial 105 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:36:09,862] Trial 106 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:36:42,900] Trial 107 finished with value: -0.7165030766494118 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.005390350172163674, 'lambda_l2': 0.017017260037500002, 'num_leaves': 326, 'feature_fraction': 0.16574602780131265, 'bagging_fraction': 0.8665447335538607, 'bagging_freq': 7, 'min_child_samples': 23, 'learning_rate': 0.16821987582180928, 'max_depth': 35, 'min_split_gain': 0.20249522090762412, 'subsample': 0.9060591654393648, 'colsample_bytree': 0.7347154771848969, 'num_iterations': 402, 'max_bin': 1002, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:36:53,606] Trial 108 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:37:20,113] Trial 109 finished with value: -0.7186876938977651 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.019197050096324345, 'lambda_l2': 0.010452628235272435, 'num_leaves': 298, 'feature_fraction': 0.26073389560129157, 'bagging_fraction': 0.8686598093212738, 'bagging_freq': 5, 'min_child_samples': 21, 'learning_rate': 0.16848610583152715, 'max_depth': 34, 'min_split_gain': 0.26639566621318106, 'subsample': 0.9320246599001075, 'colsample_bytree': 0.8655976873208371, 'num_iterations': 307, 'max_bin': 876, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:37:20,668] Trial 110 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:37:21,412] Trial 111 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:37:22,424] Trial 112 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:37:35,655] Trial 113 finished with value: -0.7079323437325031 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.06647613318360363, 'lambda_l2': 0.009932695948164443, 'num_leaves': 319, 'feature_fraction': 0.12615285018087025, 'bagging_fraction': 0.8907798025444328, 'bagging_freq': 4, 'min_child_samples': 25, 'learning_rate': 0.4859820591988086, 'max_depth': 32, 'min_split_gain': 0.17114299265682845, 'subsample': 0.9351717924591428, 'colsample_bytree': 0.8920062864165269, 'num_iterations': 195, 'max_bin': 920, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:37:42,114] Trial 114 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:37:43,774] Trial 115 finished with value: -0.7120345924652233 and parameters: {'objective': 'regression_l2', 'boosting_type': 'gbdt', 'linear_tree': True, 'lambda_l1': 0.0078317569508286, 'lambda_l2': 0.001200391448830412, 'num_leaves': 323, 'feature_fraction': 0.11857496628991993, 'bagging_fraction': 0.9817274705909967, 'bagging_freq': 4, 'min_child_samples': 32, 'learning_rate': 0.1936977220882864, 'max_depth': 36, 'min_split_gain': 0.22783259206158166, 'subsample': 0.8473334664007881, 'colsample_bytree': 0.7702569301375888, 'num_iterations': 190, 'max_bin': 837, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:37:44,418] Trial 116 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:37:45,421] Trial 117 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:37:59,580] Trial 118 finished with value: -0.7119125097809407 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0020100150636135398, 'lambda_l2': 0.003860097441396316, 'num_leaves': 333, 'feature_fraction': 0.10601377769799003, 'bagging_fraction': 0.9175986171482492, 'bagging_freq': 3, 'min_child_samples': 26, 'learning_rate': 0.16668578425416294, 'max_depth': 39, 'min_split_gain': 0.20721319139541677, 'subsample': 0.9039465398875463, 'colsample_bytree': 0.9523123399353564, 'num_iterations': 224, 'max_bin': 881, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:38:00,137] Trial 119 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:38:00,884] Trial 120 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:38:11,973] Trial 121 finished with value: -0.6969590730647695 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0022609289238406474, 'lambda_l2': 0.0030489645069905758, 'num_leaves': 318, 'feature_fraction': 0.19036632297839123, 'bagging_fraction': 0.8983126309941144, 'bagging_freq': 3, 'min_child_samples': 31, 'learning_rate': 0.2560558878726552, 'max_depth': 37, 'min_split_gain': 0.19052114547060878, 'subsample': 0.8144252158578121, 'colsample_bytree': 0.8955016094941558, 'num_iterations': 183, 'max_bin': 875, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:38:24,699] Trial 122 finished with value: -0.7099490453857763 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0019537599139326915, 'lambda_l2': 0.0030739823959983234, 'num_leaves': 354, 'feature_fraction': 0.189371941654894, 'bagging_fraction': 0.8909703993932353, 'bagging_freq': 4, 'min_child_samples': 27, 'learning_rate': 0.09773586176054873, 'max_depth': 37, 'min_split_gain': 0.2582067524533295, 'subsample': 0.816300139378579, 'colsample_bytree': 0.889105790085105, 'num_iterations': 192, 'max_bin': 941, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:38:26,898] Trial 123 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:38:30,289] Trial 124 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:38:32,270] Trial 125 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:38:33,122] Trial 126 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:38:34,578] Trial 127 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:38:36,131] Trial 128 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:38:37,509] Trial 129 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:38:39,924] Trial 130 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:38:41,026] Trial 131 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:38:41,852] Trial 132 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:38:46,813] Trial 133 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:38:47,687] Trial 134 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:38:54,770] Trial 135 finished with value: -0.702645789878029 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0023763943727976456, 'lambda_l2': 0.004604611401311653, 'num_leaves': 323, 'feature_fraction': 0.13092968700891675, 'bagging_fraction': 0.8928172807216881, 'bagging_freq': 3, 'min_child_samples': 29, 'learning_rate': 0.4881484960472183, 'max_depth': 36, 'min_split_gain': 0.16138564654984272, 'subsample': 0.8628221652477497, 'colsample_bytree': 0.9291879995596264, 'num_iterations': 103, 'max_bin': 1004, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:38:55,840] Trial 136 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:39:03,580] Trial 137 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:39:04,644] Trial 138 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:39:05,398] Trial 139 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:39:06,686] Trial 140 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:39:07,491] Trial 141 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:39:13,667] Trial 142 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:39:14,483] Trial 143 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:39:15,614] Trial 144 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:39:17,847] Trial 145 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:39:18,936] Trial 146 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:39:21,096] Trial 147 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:39:21,848] Trial 148 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:39:24,085] Trial 149 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:39:24,854] Trial 150 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:39:25,539] Trial 151 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:39:26,746] Trial 152 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:39:27,437] Trial 153 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:40:03,076] Trial 154 finished with value: -0.7106564676049942 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.030311758584191866, 'lambda_l2': 0.015620364806994802, 'num_leaves': 324, 'feature_fraction': 0.25681807950045926, 'bagging_fraction': 0.9157584280964899, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.7976836891099556, 'max_depth': 33, 'min_split_gain': 0.15636353052585228, 'subsample': 0.7952039799362853, 'colsample_bytree': 0.9266602189438375, 'num_iterations': 364, 'max_bin': 970, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:40:33,336] Trial 155 finished with value: -0.7140118807861326 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.024710899618709908, 'lambda_l2': 0.017274086075460906, 'num_leaves': 351, 'feature_fraction': 0.16389525767362648, 'bagging_fraction': 0.9286282001328536, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.2238371591735691, 'max_depth': 34, 'min_split_gain': 0.1878318342960097, 'subsample': 0.8063992617378045, 'colsample_bytree': 0.9272023079854976, 'num_iterations': 390, 'max_bin': 911, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:40:34,649] Trial 156 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:40:35,799] Trial 157 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:40:37,289] Trial 158 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:40:38,620] Trial 159 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:40:56,771] Trial 160 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:40:58,012] Trial 161 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:40:59,305] Trial 162 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:41:05,187] Trial 163 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:41:06,872] Trial 164 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:41:31,143] Trial 165 finished with value: -0.718649620916989 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0907351110740857, 'lambda_l2': 0.015114492177564286, 'num_leaves': 296, 'feature_fraction': 0.22002847560705613, 'bagging_fraction': 0.8869010047040953, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.9958249608463402, 'max_depth': 35, 'min_split_gain': 0.251696898473351, 'subsample': 0.935155379089424, 'colsample_bytree': 0.8529522677770447, 'num_iterations': 243, 'max_bin': 950, 'seed': 1338}. Best is trial 94 with value: -0.7224108043167705.\n",
      "[I 2024-06-13 14:41:56,853] Trial 166 finished with value: -0.7245187316987569 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.09786054589799595, 'lambda_l2': 0.014498634708052087, 'num_leaves': 373, 'feature_fraction': 0.22805120507046156, 'bagging_fraction': 0.8806999506027081, 'bagging_freq': 6, 'min_child_samples': 19, 'learning_rate': 0.7916674979741871, 'max_depth': 35, 'min_split_gain': 0.2719532839375701, 'subsample': 0.922423132095302, 'colsample_bytree': 0.8532603333723895, 'num_iterations': 234, 'max_bin': 952, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:41:57,592] Trial 167 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:41:59,210] Trial 168 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:42:03,000] Trial 169 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:42:03,836] Trial 170 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:42:04,527] Trial 171 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:42:05,212] Trial 172 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:42:06,220] Trial 173 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:42:07,467] Trial 174 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:42:08,474] Trial 175 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:42:09,319] Trial 176 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:42:11,692] Trial 177 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:42:37,716] Trial 178 finished with value: -0.7114137541363941 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.0036247816035372637, 'lambda_l2': 0.01029253645878786, 'num_leaves': 342, 'feature_fraction': 0.17860875981011848, 'bagging_fraction': 0.8521384474336794, 'bagging_freq': 6, 'min_child_samples': 24, 'learning_rate': 0.13776218055392048, 'max_depth': 31, 'min_split_gain': 0.23907440889532366, 'subsample': 0.9208560111002765, 'colsample_bytree': 0.8417368993167553, 'num_iterations': 356, 'max_bin': 995, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:42:38,431] Trial 179 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:42:39,417] Trial 180 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:42:40,741] Trial 181 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:43:06,641] Trial 182 finished with value: -0.7188619394964948 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.07048611462481907, 'lambda_l2': 0.004380737309679765, 'num_leaves': 357, 'feature_fraction': 0.13479204844063453, 'bagging_fraction': 0.8595304973591776, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.746489258114532, 'max_depth': 29, 'min_split_gain': 0.24511109345245274, 'subsample': 0.8665036166720803, 'colsample_bytree': 0.8650793758923083, 'num_iterations': 336, 'max_bin': 1023, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:43:07,924] Trial 183 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:43:08,766] Trial 184 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:43:32,522] Trial 185 finished with value: -0.7100887356662993 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.4058380438037095, 'lambda_l2': 0.0006805572584872289, 'num_leaves': 384, 'feature_fraction': 0.16524033669638205, 'bagging_fraction': 0.883929446730536, 'bagging_freq': 5, 'min_child_samples': 26, 'learning_rate': 0.05544113682620121, 'max_depth': 28, 'min_split_gain': 0.3007866065320612, 'subsample': 0.9575725180825962, 'colsample_bytree': 0.8043811044145155, 'num_iterations': 366, 'max_bin': 934, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:43:33,292] Trial 186 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:43:34,567] Trial 187 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:43:36,858] Trial 188 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:43:37,879] Trial 189 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:43:38,594] Trial 190 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:43:39,506] Trial 191 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:43:40,248] Trial 192 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:44:10,480] Trial 193 finished with value: -0.7148092221667753 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.011300832774237548, 'lambda_l2': 0.00837298718423103, 'num_leaves': 323, 'feature_fraction': 0.21163183025399218, 'bagging_fraction': 0.8472203723232741, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.7541928282796704, 'max_depth': 36, 'min_split_gain': 0.26368160572336236, 'subsample': 0.9055217358377117, 'colsample_bytree': 0.8848424606102246, 'num_iterations': 383, 'max_bin': 973, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:44:11,107] Trial 194 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:44:11,837] Trial 195 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:44:18,481] Trial 196 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:44:19,403] Trial 197 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:44:20,099] Trial 198 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:44:50,964] Trial 199 finished with value: -0.7157437594836931 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.004667982780585923, 'lambda_l2': 8.315744144430786, 'num_leaves': 343, 'feature_fraction': 0.18429110482519198, 'bagging_fraction': 0.940729172715989, 'bagging_freq': 6, 'min_child_samples': 21, 'learning_rate': 0.22942117576339655, 'max_depth': 39, 'min_split_gain': 0.29867258873756486, 'subsample': 0.9269207871345133, 'colsample_bytree': 0.8299032273147241, 'num_iterations': 393, 'max_bin': 951, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:45:21,609] Trial 200 finished with value: -0.7231109230153971 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.005432108025464854, 'lambda_l2': 4.182102712579693, 'num_leaves': 347, 'feature_fraction': 0.17345458747084616, 'bagging_fraction': 0.9735091008941305, 'bagging_freq': 6, 'min_child_samples': 21, 'learning_rate': 0.21283459898058033, 'max_depth': 39, 'min_split_gain': 0.2949166966836319, 'subsample': 0.9360691794937516, 'colsample_bytree': 0.8345565926670654, 'num_iterations': 387, 'max_bin': 928, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:45:50,086] Trial 201 finished with value: -0.7182163270219246 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.005773263322135336, 'lambda_l2': 8.055248568211555, 'num_leaves': 346, 'feature_fraction': 0.18447855821900938, 'bagging_fraction': 0.9759500964648246, 'bagging_freq': 6, 'min_child_samples': 21, 'learning_rate': 0.21353224664520692, 'max_depth': 38, 'min_split_gain': 0.29037796263074406, 'subsample': 0.9281785134474677, 'colsample_bytree': 0.8269172333614009, 'num_iterations': 389, 'max_bin': 925, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:45:50,705] Trial 202 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:45:57,035] Trial 203 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:45:57,808] Trial 204 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:45:58,784] Trial 205 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:45:59,644] Trial 206 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:46:00,497] Trial 207 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:46:01,209] Trial 208 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:46:02,494] Trial 209 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:46:03,164] Trial 210 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:46:04,353] Trial 211 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:46:05,093] Trial 212 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:46:05,964] Trial 213 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:46:07,176] Trial 214 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:46:21,535] Trial 215 finished with value: -0.717997479514058 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.059688017292064e-06, 'lambda_l2': 9.497722740178256, 'num_leaves': 430, 'feature_fraction': 0.14405022914444823, 'bagging_fraction': 0.9818209332996406, 'bagging_freq': 5, 'min_child_samples': 21, 'learning_rate': 0.00042926304012226964, 'max_depth': 34, 'min_split_gain': 0.2197019313681634, 'subsample': 0.878077207289854, 'colsample_bytree': 0.8614863729637424, 'num_iterations': 189, 'max_bin': 961, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:46:35,996] Trial 216 finished with value: -0.7234167768846765 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.19278554539350817, 'lambda_l2': 1.5777743489835405, 'num_leaves': 430, 'feature_fraction': 0.1363818477526065, 'bagging_fraction': 0.9856189810733693, 'bagging_freq': 5, 'min_child_samples': 21, 'learning_rate': 0.24801327396983083, 'max_depth': 34, 'min_split_gain': 0.21651393694465687, 'subsample': 0.8859164600321476, 'colsample_bytree': 0.8592067960585178, 'num_iterations': 170, 'max_bin': 938, 'seed': 1338}. Best is trial 166 with value: -0.7245187316987569.\n",
      "[I 2024-06-13 14:46:53,652] Trial 217 finished with value: -0.7310306029645008 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.6787324910379653e-07, 'lambda_l2': 1.2726381459198342, 'num_leaves': 421, 'feature_fraction': 0.13955782149228932, 'bagging_fraction': 0.9925240020686029, 'bagging_freq': 5, 'min_child_samples': 20, 'learning_rate': 0.23888402003523743, 'max_depth': 34, 'min_split_gain': 0.21658353208372347, 'subsample': 0.8847690420944571, 'colsample_bytree': 0.8457952666351153, 'num_iterations': 188, 'max_bin': 929, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:46:54,399] Trial 218 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:46:56,155] Trial 219 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:46:57,212] Trial 220 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:13,394] Trial 221 finished with value: -0.7226406352008619 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 7.28326149426675e-08, 'lambda_l2': 0.5542574642345715, 'num_leaves': 418, 'feature_fraction': 0.10047082324870182, 'bagging_fraction': 0.9871237250048727, 'bagging_freq': 5, 'min_child_samples': 21, 'learning_rate': 0.00042977518049040807, 'max_depth': 33, 'min_split_gain': 0.19716109514679273, 'subsample': 0.8923337405483243, 'colsample_bytree': 0.8642008798256987, 'num_iterations': 184, 'max_bin': 953, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:47:14,156] Trial 222 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:15,167] Trial 223 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:16,224] Trial 224 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:31,515] Trial 225 finished with value: -0.7192288242525859 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 7.562972316537987e-08, 'lambda_l2': 0.5410688962232408, 'num_leaves': 414, 'feature_fraction': 0.10392456162999644, 'bagging_fraction': 0.9599505830885341, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.00044517874842564206, 'max_depth': 34, 'min_split_gain': 0.21170446527664263, 'subsample': 0.9323973420622564, 'colsample_bytree': 0.8283126424793411, 'num_iterations': 185, 'max_bin': 938, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:47:32,251] Trial 226 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:33,589] Trial 227 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:47:34,693] Trial 228 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:35,660] Trial 229 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:48,765] Trial 230 finished with value: -0.7139622602755815 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 4.344778585473421e-07, 'lambda_l2': 6.986343705561964, 'num_leaves': 437, 'feature_fraction': 0.12546043082272734, 'bagging_fraction': 0.951176153793544, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.00026054570038146283, 'max_depth': 33, 'min_split_gain': 0.312367787091342, 'subsample': 0.928827330915132, 'colsample_bytree': 0.8129459616385519, 'num_iterations': 190, 'max_bin': 968, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:47:49,531] Trial 231 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:52,205] Trial 232 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:47:53,224] Trial 233 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:54,832] Trial 234 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:47:56,067] Trial 235 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:47:57,063] Trial 236 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:58,048] Trial 237 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:47:59,046] Trial 238 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:48:20,330] Trial 239 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:48:38,357] Trial 240 finished with value: -0.7239231073574113 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.7288034749281646e-08, 'lambda_l2': 1.5960731535418924, 'num_leaves': 405, 'feature_fraction': 0.1654037559277414, 'bagging_fraction': 0.9998498778098545, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.13047543936607436, 'max_depth': 38, 'min_split_gain': 0.23145884476608794, 'subsample': 0.14237536646194177, 'colsample_bytree': 0.8265137582728925, 'num_iterations': 191, 'max_bin': 955, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:48:39,765] Trial 241 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:48:41,898] Trial 242 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:48:43,509] Trial 243 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:48:44,515] Trial 244 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:48:46,019] Trial 245 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:48:47,610] Trial 246 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:48:48,493] Trial 247 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:48:49,613] Trial 248 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:48:50,530] Trial 249 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:48:51,528] Trial 250 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:48:52,447] Trial 251 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:48:53,429] Trial 252 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:48:56,329] Trial 253 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:48:58,460] Trial 254 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:48:59,317] Trial 255 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:00,448] Trial 256 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:49:02,927] Trial 257 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:49:03,859] Trial 258 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:04,650] Trial 259 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:05,620] Trial 260 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:06,550] Trial 261 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:07,518] Trial 262 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:09,265] Trial 263 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:49:10,240] Trial 264 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:26,896] Trial 265 finished with value: -0.7183500096963191 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.1321714843318797e-05, 'lambda_l2': 0.00664754289043635, 'num_leaves': 329, 'feature_fraction': 0.1650782740260424, 'bagging_fraction': 0.9001333835769525, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.000355010220024879, 'max_depth': 29, 'min_split_gain': 0.22694994852055692, 'subsample': 0.8583127123853134, 'colsample_bytree': 0.8873925047401467, 'num_iterations': 206, 'max_bin': 892, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:49:27,486] Trial 266 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:28,332] Trial 267 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:29,239] Trial 268 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:30,241] Trial 269 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:31,327] Trial 270 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:32,435] Trial 271 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:49:33,205] Trial 272 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:49:42,518] Trial 273 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:49:53,798] Trial 274 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:49:54,821] Trial 275 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:50:16,049] Trial 276 finished with value: -0.7196191876676563 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.41699968985461217, 'lambda_l2': 0.005650938943290194, 'num_leaves': 305, 'feature_fraction': 0.22668609157273034, 'bagging_fraction': 0.8814284342099675, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.18321755641257975, 'max_depth': 41, 'min_split_gain': 0.16076510655850093, 'subsample': 0.9247122946553545, 'colsample_bytree': 0.8610900825036061, 'num_iterations': 249, 'max_bin': 953, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:50:16,658] Trial 277 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:50:17,510] Trial 278 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:50:18,291] Trial 279 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:50:18,692] Trial 280 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:50:19,264] Trial 281 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:50:20,221] Trial 282 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:50:42,003] Trial 283 finished with value: -0.7255911187667583 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.015460645831197434, 'lambda_l2': 0.008662693254386957, 'num_leaves': 307, 'feature_fraction': 0.24489536439633805, 'bagging_fraction': 0.9562009437674128, 'bagging_freq': 6, 'min_child_samples': 21, 'learning_rate': 0.0003472560064280793, 'max_depth': 35, 'min_split_gain': 0.2428067311596232, 'subsample': 0.8778304504950128, 'colsample_bytree': 0.9216763371132346, 'num_iterations': 211, 'max_bin': 949, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:50:42,576] Trial 284 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:50:45,930] Trial 285 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:51:10,844] Trial 286 finished with value: -0.6593318284698052 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.007842302574981176, 'lambda_l2': 0.009046781975057098, 'num_leaves': 300, 'feature_fraction': 0.24261775774333902, 'bagging_fraction': 0.9707092416897124, 'bagging_freq': 6, 'min_child_samples': 18, 'learning_rate': 0.0005178348479264529, 'max_depth': -1, 'min_split_gain': 0.2683702635829154, 'subsample': 0.8878321634911029, 'colsample_bytree': 0.8384418292904422, 'num_iterations': 221, 'max_bin': 890, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:51:11,668] Trial 287 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:51:12,549] Trial 288 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:51:29,475] Trial 289 finished with value: -0.718697421208595 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.1113348776741178, 'lambda_l2': 0.00380750203525651, 'num_leaves': 303, 'feature_fraction': 0.132605346109157, 'bagging_fraction': 0.9857643480450081, 'bagging_freq': 5, 'min_child_samples': 24, 'learning_rate': 0.18235375604669882, 'max_depth': 36, 'min_split_gain': 0.2485062706808015, 'subsample': 0.944989665806224, 'colsample_bytree': 0.6295522481067498, 'num_iterations': 214, 'max_bin': 910, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:51:47,166] Trial 290 finished with value: -0.7187723605652498 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.11948240658894464, 'lambda_l2': 0.002979780724084246, 'num_leaves': 288, 'feature_fraction': 0.10003598848224138, 'bagging_fraction': 0.986715930855864, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.19953215792613666, 'max_depth': 36, 'min_split_gain': 0.2607297969497297, 'subsample': 0.9451360683583231, 'colsample_bytree': 0.6958537685058587, 'num_iterations': 222, 'max_bin': 905, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:51:47,732] Trial 291 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:52:05,329] Trial 292 finished with value: -0.7164558081650587 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.13476121040049177, 'lambda_l2': 0.1340816153859139, 'num_leaves': 280, 'feature_fraction': 0.1002849272500545, 'bagging_fraction': 0.997939003622165, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.23034487141130355, 'max_depth': 35, 'min_split_gain': 0.2883698899150033, 'subsample': 0.9425469339343218, 'colsample_bytree': 0.6266310889550252, 'num_iterations': 221, 'max_bin': 923, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:52:22,040] Trial 293 finished with value: -0.7241414993215857 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.34339416371471987, 'lambda_l2': 1.5866792141168338, 'num_leaves': 289, 'feature_fraction': 0.11344341977443952, 'bagging_fraction': 0.9975545423942417, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.3540225705130868, 'max_depth': 35, 'min_split_gain': 0.27574629660655153, 'subsample': 0.9611741414215893, 'colsample_bytree': 0.6711148039895345, 'num_iterations': 226, 'max_bin': 926, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:52:22,506] Trial 294 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:52:23,213] Trial 295 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:52:42,792] Trial 296 finished with value: -0.7241012503553044 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.6073539147814317, 'lambda_l2': 1.3969100873010967, 'num_leaves': 291, 'feature_fraction': 0.13136833751270707, 'bagging_fraction': 0.979266500456892, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.28245269461177264, 'max_depth': 35, 'min_split_gain': 0.2800845620584075, 'subsample': 0.9481409057739355, 'colsample_bytree': 0.6919358948243491, 'num_iterations': 273, 'max_bin': 926, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:52:43,363] Trial 297 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:52:44,140] Trial 298 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:52:44,903] Trial 299 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:52:45,758] Trial 300 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:52:46,401] Trial 301 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:53:04,350] Trial 302 finished with value: -0.7281953847096062 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.16386494481899938, 'lambda_l2': 0.8010364701016277, 'num_leaves': 284, 'feature_fraction': 0.15584444832339406, 'bagging_fraction': 0.9831565492794891, 'bagging_freq': 5, 'min_child_samples': 20, 'learning_rate': 0.26878058908209906, 'max_depth': 36, 'min_split_gain': 0.488238177067463, 'subsample': 0.9409934483964736, 'colsample_bytree': 0.6575177087904326, 'num_iterations': 224, 'max_bin': 929, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:53:04,920] Trial 303 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:53:05,582] Trial 304 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:53:06,620] Trial 305 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:53:07,253] Trial 306 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:53:29,392] Trial 307 finished with value: -0.7198307308598562 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.36122217712592253, 'lambda_l2': 0.5883037083277003, 'num_leaves': 302, 'feature_fraction': 0.2795974008704785, 'bagging_fraction': 0.9987653617327117, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.282641001924093, 'max_depth': 38, 'min_split_gain': 0.24896762348499846, 'subsample': 0.9524105339682358, 'colsample_bytree': 0.6467061585678804, 'num_iterations': 235, 'max_bin': 932, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:53:29,986] Trial 308 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:53:49,013] Trial 309 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 14:53:49,862] Trial 310 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:53:50,828] Trial 311 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:53:51,711] Trial 312 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:53:52,513] Trial 313 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:54:10,870] Trial 314 finished with value: -0.6316122284347445 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.1765660944893369, 'lambda_l2': 0.18429763119021214, 'num_leaves': 306, 'feature_fraction': 0.10195477622647266, 'bagging_fraction': 0.9674732482028277, 'bagging_freq': 5, 'min_child_samples': 18, 'learning_rate': 0.3218793174034423, 'max_depth': 40, 'min_split_gain': 0.31167862706881794, 'subsample': 0.9520729927175582, 'colsample_bytree': 0.6133202529369405, 'num_iterations': 206, 'max_bin': 924, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:54:11,480] Trial 315 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:54:12,038] Trial 316 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:54:14,448] Trial 317 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:54:15,307] Trial 318 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:54:16,502] Trial 319 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:54:17,318] Trial 320 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:54:19,870] Trial 321 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:54:39,339] Trial 322 finished with value: -0.7295602494086041 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.16083028522316106, 'lambda_l2': 0.3551873322545336, 'num_leaves': 278, 'feature_fraction': 0.17789422003466177, 'bagging_fraction': 0.998641945134802, 'bagging_freq': 5, 'min_child_samples': 20, 'learning_rate': 0.1452851603266604, 'max_depth': 35, 'min_split_gain': 0.2501035138920804, 'subsample': 0.9411228276090637, 'colsample_bytree': 0.6450807222359661, 'num_iterations': 203, 'max_bin': 957, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:54:39,850] Trial 323 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:54:42,976] Trial 324 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:54:48,655] Trial 325 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:54:49,429] Trial 326 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:54:50,084] Trial 327 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:55:03,127] Trial 328 finished with value: -0.7268257595921541 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.07699048514085237, 'lambda_l2': 1.0074146172015124, 'num_leaves': 243, 'feature_fraction': 0.12353960145446422, 'bagging_fraction': 0.9994713569216581, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.00044171427156526404, 'max_depth': 35, 'min_split_gain': 0.22093674093202817, 'subsample': 0.9244466571962229, 'colsample_bytree': 0.7362334888844965, 'num_iterations': 176, 'max_bin': 525, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:55:10,043] Trial 329 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:55:11,157] Trial 330 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:55:11,742] Trial 331 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:55:13,453] Trial 332 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:55:58,432] Trial 333 finished with value: -0.727148995990256 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.056504463510334536, 'lambda_l2': 1.0525313653285318, 'num_leaves': 240, 'feature_fraction': 0.15702484659062854, 'bagging_fraction': 0.9507349995241636, 'bagging_freq': 4, 'min_child_samples': 21, 'learning_rate': 0.0004334392730481116, 'max_depth': 33, 'min_split_gain': 0.19455997286947346, 'subsample': 0.3803385960721676, 'colsample_bytree': 0.6759677736277095, 'num_iterations': 569, 'max_bin': 528, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:55:59,089] Trial 334 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:55:59,634] Trial 335 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:56:01,149] Trial 336 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:56:01,739] Trial 337 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:56:39,770] Trial 338 finished with value: -0.7232456405506831 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.6227366875163628e-08, 'lambda_l2': 0.6424045993895565, 'num_leaves': 250, 'feature_fraction': 0.11682093509963103, 'bagging_fraction': 0.9588710466067631, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.00040564548143069, 'max_depth': 37, 'min_split_gain': 0.19622436159320997, 'subsample': 0.37645758827392617, 'colsample_bytree': 0.6986648485495057, 'num_iterations': 519, 'max_bin': 512, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:56:42,015] Trial 339 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:57:25,838] Trial 340 finished with value: -0.7248799604476062 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.9591828995191294e-08, 'lambda_l2': 0.5267623366194031, 'num_leaves': 247, 'feature_fraction': 0.11639203693562271, 'bagging_fraction': 0.9553791081768445, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.00026304838976801045, 'max_depth': 38, 'min_split_gain': 0.17474951089377647, 'subsample': 0.644961424906485, 'colsample_bytree': 0.741656054819811, 'num_iterations': 612, 'max_bin': 545, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:57:30,756] Trial 341 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:57:31,017] Trial 342 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:57:37,031] Trial 343 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 14:57:39,353] Trial 344 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:57:39,856] Trial 345 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:57:40,700] Trial 346 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:57:41,552] Trial 347 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:57:42,305] Trial 348 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:57:43,001] Trial 349 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:57:43,535] Trial 350 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:57:44,134] Trial 351 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:57:44,614] Trial 352 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:57:45,637] Trial 353 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:58:02,408] Trial 354 finished with value: -0.7240990902828083 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.09239770360362798, 'lambda_l2': 0.4144673418421634, 'num_leaves': 270, 'feature_fraction': 0.1330292345196254, 'bagging_fraction': 0.9676909022219795, 'bagging_freq': 5, 'min_child_samples': 23, 'learning_rate': 0.0001540506397706605, 'max_depth': 33, 'min_split_gain': 0.2642824310336253, 'subsample': 0.55556995069917, 'colsample_bytree': 0.7375722811238565, 'num_iterations': 235, 'max_bin': 503, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:58:03,080] Trial 355 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:58:03,685] Trial 356 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:58:04,271] Trial 357 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:58:05,369] Trial 358 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:58:05,935] Trial 359 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:58:07,382] Trial 360 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:58:07,917] Trial 361 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:58:27,083] Trial 362 finished with value: -0.7227205607666543 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.07317778760900101, 'lambda_l2': 0.22225841571573593, 'num_leaves': 291, 'feature_fraction': 0.11625418870547313, 'bagging_fraction': 0.9859356325997889, 'bagging_freq': 8, 'min_child_samples': 24, 'learning_rate': 0.0001759522883808151, 'max_depth': 34, 'min_split_gain': 0.2152121805833702, 'subsample': 0.703291543039742, 'colsample_bytree': 0.7309033975263975, 'num_iterations': 265, 'max_bin': 617, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:58:29,474] Trial 363 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:58:29,884] Trial 364 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:58:30,434] Trial 365 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:58:32,162] Trial 366 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:58:51,135] Trial 367 finished with value: -0.7232972407998063 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.2540338816682164, 'lambda_l2': 0.9711035949640179, 'num_leaves': 250, 'feature_fraction': 0.11690227632290637, 'bagging_fraction': 0.952967787457849, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.00012843998052099263, 'max_depth': 37, 'min_split_gain': 0.12215472377293934, 'subsample': 0.9535914556743157, 'colsample_bytree': 0.4929813212813402, 'num_iterations': 256, 'max_bin': 590, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:58:53,313] Trial 368 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:58:53,644] Trial 369 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:58:54,295] Trial 370 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:58:54,816] Trial 371 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:59:03,530] Trial 372 finished with value: -0.7140664757549764 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.2048610317109024e-08, 'lambda_l2': 0.22457410033100578, 'num_leaves': 247, 'feature_fraction': 0.11663314623383697, 'bagging_fraction': 0.9717824606792007, 'bagging_freq': 4, 'min_child_samples': 28, 'learning_rate': 0.00015277006454028532, 'max_depth': 37, 'min_split_gain': 0.16506517987602837, 'subsample': 0.6964764092507896, 'colsample_bytree': 0.6481165042400376, 'num_iterations': 138, 'max_bin': 526, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:59:03,970] Trial 373 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:59:06,766] Trial 374 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 14:59:07,259] Trial 375 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:59:07,905] Trial 376 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:59:08,963] Trial 377 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:59:10,412] Trial 378 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:59:11,067] Trial 379 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:59:11,814] Trial 380 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:59:29,884] Trial 381 finished with value: -0.7156535452124648 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.8348346487146264, 'lambda_l2': 2.3887266091510746, 'num_leaves': 278, 'feature_fraction': 0.14256016569881189, 'bagging_fraction': 0.9996423296599931, 'bagging_freq': 4, 'min_child_samples': 17, 'learning_rate': 0.006875667657537912, 'max_depth': 41, 'min_split_gain': 0.19097258389802282, 'subsample': 0.3663209462006677, 'colsample_bytree': 0.7130456892745893, 'num_iterations': 228, 'max_bin': 459, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:59:30,486] Trial 382 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:59:31,032] Trial 383 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:59:31,604] Trial 384 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:59:32,386] Trial 385 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 14:59:44,705] Trial 386 finished with value: -0.7249531821568191 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 5.578739937600401e-08, 'lambda_l2': 0.0022396499636652234, 'num_leaves': 220, 'feature_fraction': 0.17149783081173878, 'bagging_fraction': 0.9396322220308845, 'bagging_freq': 5, 'min_child_samples': 22, 'learning_rate': 0.0002958530968780136, 'max_depth': 38, 'min_split_gain': 0.23819219432925726, 'subsample': 0.9397033210872692, 'colsample_bytree': 0.7405480398614432, 'num_iterations': 155, 'max_bin': 559, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 14:59:45,189] Trial 387 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 14:59:45,967] Trial 388 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:59:46,602] Trial 389 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 14:59:47,161] Trial 390 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:00:33,271] Trial 391 finished with value: -0.7310113143157768 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.0596321158511593e-07, 'lambda_l2': 0.9656928966419734, 'num_leaves': 421, 'feature_fraction': 0.11575751039473368, 'bagging_fraction': 0.9676387840164382, 'bagging_freq': 5, 'min_child_samples': 20, 'learning_rate': 0.0002888191072484732, 'max_depth': 32, 'min_split_gain': 0.19885029799982815, 'subsample': 0.7090348784007843, 'colsample_bytree': 0.7139044003703252, 'num_iterations': 554, 'max_bin': 528, 'seed': 1338}. Best is trial 217 with value: -0.7310306029645008.\n",
      "[I 2024-06-13 15:00:34,100] Trial 392 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:01:20,810] Trial 393 finished with value: -0.7339049060431766 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.660554930446781e-07, 'lambda_l2': 0.7206974223098874, 'num_leaves': 420, 'feature_fraction': 0.14873590049924637, 'bagging_fraction': 0.9662324303430261, 'bagging_freq': 5, 'min_child_samples': 20, 'learning_rate': 0.00027738864704250263, 'max_depth': 32, 'min_split_gain': 0.1993196257690939, 'subsample': 0.6746028834694999, 'colsample_bytree': 0.7503304378009429, 'num_iterations': 545, 'max_bin': 554, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:01:52,222] Trial 394 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:01:53,143] Trial 395 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:01:54,081] Trial 396 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:01:55,469] Trial 397 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:01:56,451] Trial 398 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:01:57,546] Trial 399 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:01:58,425] Trial 400 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:01:59,275] Trial 401 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:00,232] Trial 402 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:01,551] Trial 403 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:02:02,315] Trial 404 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:03,479] Trial 405 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:02:04,497] Trial 406 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:02:07,296] Trial 407 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:02:07,982] Trial 408 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:08,806] Trial 409 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:25,075] Trial 410 finished with value: -0.7289146598456474 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.697075513180506e-08, 'lambda_l2': 3.275171208239449, 'num_leaves': 257, 'feature_fraction': 0.11739827771957605, 'bagging_fraction': 0.9634533629681217, 'bagging_freq': 9, 'min_child_samples': 17, 'learning_rate': 0.00022180720623617375, 'max_depth': 35, 'min_split_gain': 0.21919270011602607, 'subsample': 0.15081090444977696, 'colsample_bytree': 0.7621137625485813, 'num_iterations': 189, 'max_bin': 520, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:02:25,732] Trial 411 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:02:26,323] Trial 412 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:26,881] Trial 413 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:27,418] Trial 414 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:27,868] Trial 415 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:28,581] Trial 416 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:02:29,137] Trial 417 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:29,724] Trial 418 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:35,219] Trial 419 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:02:37,069] Trial 420 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:02:37,579] Trial 421 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:02:38,420] Trial 422 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:02:40,923] Trial 423 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:02:41,703] Trial 424 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:02:42,651] Trial 425 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:02:43,859] Trial 426 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:02:45,013] Trial 427 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:02:45,633] Trial 428 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:02:57,971] Trial 429 finished with value: -0.7223702074856058 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 9.510312422999457e-08, 'lambda_l2': 3.011149605171964, 'num_leaves': 259, 'feature_fraction': 0.15066978763342562, 'bagging_fraction': 0.9996059849065779, 'bagging_freq': 5, 'min_child_samples': 25, 'learning_rate': 0.0003221115457621009, 'max_depth': 36, 'min_split_gain': 0.11991088802949702, 'subsample': 0.4146398856180995, 'colsample_bytree': 0.6699500875985868, 'num_iterations': 174, 'max_bin': 550, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:02:58,545] Trial 430 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:03:03,554] Trial 431 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:03:04,258] Trial 432 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:05,118] Trial 433 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:10,582] Trial 434 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:03:12,589] Trial 435 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:03:13,440] Trial 436 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:14,435] Trial 437 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:15,003] Trial 438 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:03:15,695] Trial 439 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:16,686] Trial 440 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:17,507] Trial 441 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:03:18,005] Trial 442 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:03:18,542] Trial 443 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:04:00,300] Trial 444 finished with value: -0.7218466114822331 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.876509781812861e-08, 'lambda_l2': 0.7073119704606483, 'num_leaves': 274, 'feature_fraction': 0.1600043515749209, 'bagging_fraction': 0.968523769390903, 'bagging_freq': 5, 'min_child_samples': 24, 'learning_rate': 0.0003281438315672102, 'max_depth': 34, 'min_split_gain': 0.2329667249525756, 'subsample': 0.4853053835589985, 'colsample_bytree': 0.4689907826639661, 'num_iterations': 578, 'max_bin': 463, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:04:01,014] Trial 445 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:04:03,031] Trial 446 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:04:05,262] Trial 447 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:04:05,755] Trial 448 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:04:06,412] Trial 449 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:04:07,037] Trial 450 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:04:09,078] Trial 451 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:04:14,204] Trial 452 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:04:27,891] Trial 453 finished with value: -0.7260281277249501 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 8.93572289589563e-08, 'lambda_l2': 0.4417277984790274, 'num_leaves': 403, 'feature_fraction': 0.10124820082705262, 'bagging_fraction': 0.9802174797710366, 'bagging_freq': 5, 'min_child_samples': 20, 'learning_rate': 0.0003228911868882633, 'max_depth': 32, 'min_split_gain': 0.24233810682341253, 'subsample': 0.4457932238761577, 'colsample_bytree': 0.4874453676605306, 'num_iterations': 169, 'max_bin': 490, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:04:28,406] Trial 454 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:04:29,065] Trial 455 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:04:42,294] Trial 456 finished with value: -0.7290101999337212 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.5307612798601266e-07, 'lambda_l2': 0.2361448897328034, 'num_leaves': 391, 'feature_fraction': 0.12778138053757443, 'bagging_fraction': 0.9388671507572411, 'bagging_freq': 4, 'min_child_samples': 20, 'learning_rate': 0.00042553575146387214, 'max_depth': 32, 'min_split_gain': 0.19869964344189828, 'subsample': 0.3970047406832103, 'colsample_bytree': 0.7030732051016046, 'num_iterations': 153, 'max_bin': 520, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:04:42,927] Trial 457 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:04:43,632] Trial 458 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:04:57,069] Trial 459 finished with value: -0.7258750783812065 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.3019627579011705e-07, 'lambda_l2': 0.21594436534023612, 'num_leaves': 395, 'feature_fraction': 0.1005567582042542, 'bagging_fraction': 0.935565013146124, 'bagging_freq': 4, 'min_child_samples': 20, 'learning_rate': 0.001386046961277253, 'max_depth': 31, 'min_split_gain': 0.20579301633186337, 'subsample': 0.6673138054319216, 'colsample_bytree': 0.4799715929155099, 'num_iterations': 163, 'max_bin': 483, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:04:57,785] Trial 460 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:05:10,608] Trial 461 finished with value: -0.7232480937162105 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.6076960400731164e-07, 'lambda_l2': 0.12388829622892295, 'num_leaves': 394, 'feature_fraction': 0.10288209519548908, 'bagging_fraction': 0.9279865700998595, 'bagging_freq': 4, 'min_child_samples': 20, 'learning_rate': 0.00045303430215919106, 'max_depth': 31, 'min_split_gain': 0.202989353854351, 'subsample': 0.6631593586391803, 'colsample_bytree': 0.5208804776154206, 'num_iterations': 153, 'max_bin': 495, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:05:11,648] Trial 462 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:05:12,564] Trial 463 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:06:22,017] Trial 464 finished with value: -0.7321932687054973 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.4180167284581543e-07, 'lambda_l2': 0.2143916045739489, 'num_leaves': 403, 'feature_fraction': 0.10242338279260721, 'bagging_fraction': 0.9339955457715751, 'bagging_freq': 4, 'min_child_samples': 18, 'learning_rate': 0.00046151230406994795, 'max_depth': 30, 'min_split_gain': 0.19292090574300025, 'subsample': 0.6614988710544845, 'colsample_bytree': 0.5086397700492833, 'num_iterations': 767, 'max_bin': 489, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:06:22,651] Trial 465 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:06:23,680] Trial 466 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:06:24,427] Trial 467 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:06:25,497] Trial 468 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:07:33,558] Trial 469 finished with value: -0.7116498458878191 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.999361643129682e-07, 'lambda_l2': 0.07183605436840411, 'num_leaves': 405, 'feature_fraction': 0.13105420770329582, 'bagging_fraction': 0.9074783750758704, 'bagging_freq': 4, 'min_child_samples': 18, 'learning_rate': 0.00039141147970571383, 'max_depth': 30, 'min_split_gain': 0.20097765740067153, 'subsample': 0.6709311819208802, 'colsample_bytree': 0.5226285837413931, 'num_iterations': 756, 'max_bin': 456, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:07:36,267] Trial 470 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:07:36,983] Trial 471 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:07:38,108] Trial 472 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:07:39,503] Trial 473 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:07:40,385] Trial 474 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:07:51,803] Trial 475 finished with value: -0.7312421644939177 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 5.360850258860242e-07, 'lambda_l2': 0.05208739032108245, 'num_leaves': 381, 'feature_fraction': 0.14286824985609803, 'bagging_fraction': 0.9384134061843908, 'bagging_freq': 4, 'min_child_samples': 20, 'learning_rate': 0.00036397871675537406, 'max_depth': 29, 'min_split_gain': 0.21997325981709753, 'subsample': 0.6469325168989309, 'colsample_bytree': 0.5038775432068449, 'num_iterations': 127, 'max_bin': 530, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:07:52,297] Trial 476 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:07:53,063] Trial 477 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:07:57,680] Trial 478 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:07:59,061] Trial 479 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:07:59,901] Trial 480 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:00,766] Trial 481 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:01,563] Trial 482 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:06,768] Trial 483 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:08:07,641] Trial 484 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:08,480] Trial 485 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:09,403] Trial 486 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:10,456] Trial 487 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:11,292] Trial 488 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:26,951] Trial 489 finished with value: -0.7273917965918018 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 7.529683896469514e-08, 'lambda_l2': 0.4528935709955691, 'num_leaves': 397, 'feature_fraction': 0.14461649323783418, 'bagging_fraction': 0.9267115764453603, 'bagging_freq': 2, 'min_child_samples': 19, 'learning_rate': 0.0010912221837600133, 'max_depth': 31, 'min_split_gain': 0.22943474575257133, 'subsample': 0.43604485916810876, 'colsample_bytree': 0.4390003000606282, 'num_iterations': 174, 'max_bin': 536, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:08:27,624] Trial 490 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:28,584] Trial 491 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:29,479] Trial 492 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:30,486] Trial 493 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:31,468] Trial 494 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:32,012] Trial 495 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:33,427] Trial 496 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:35,166] Trial 497 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:08:48,833] Trial 498 finished with value: -0.7269205171807499 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 9.271637858024498e-08, 'lambda_l2': 0.18299443749486421, 'num_leaves': 379, 'feature_fraction': 0.11855223975845978, 'bagging_fraction': 0.9734259539012351, 'bagging_freq': 4, 'min_child_samples': 20, 'learning_rate': 0.0002705231254803428, 'max_depth': 33, 'min_split_gain': 0.21069226356573445, 'subsample': 0.6765971943741063, 'colsample_bytree': 0.5073532819432649, 'num_iterations': 153, 'max_bin': 518, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:08:49,529] Trial 499 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:50,969] Trial 500 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:08:51,853] Trial 501 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:52,463] Trial 502 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:53,122] Trial 503 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:53,975] Trial 504 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:54,884] Trial 505 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:08:55,583] Trial 506 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:08:56,373] Trial 507 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:10,613] Trial 508 finished with value: -0.7229187504287342 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.1751941144800671e-07, 'lambda_l2': 0.5776166584298451, 'num_leaves': 414, 'feature_fraction': 0.11639507782327767, 'bagging_fraction': 0.9580671975594022, 'bagging_freq': 2, 'min_child_samples': 21, 'learning_rate': 0.00031639190552441274, 'max_depth': 33, 'min_split_gain': 0.25786971021981425, 'subsample': 0.4019175290046437, 'colsample_bytree': 0.48594933702038945, 'num_iterations': 176, 'max_bin': 544, 'seed': 1338}. Best is trial 393 with value: -0.7339049060431766.\n",
      "[I 2024-06-13 15:09:11,328] Trial 509 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:12,146] Trial 510 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:12,957] Trial 511 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:14,043] Trial 512 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:14,881] Trial 513 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:15,613] Trial 514 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:09:16,346] Trial 515 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:17,212] Trial 516 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:18,110] Trial 517 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:18,912] Trial 518 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:19,791] Trial 519 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:20,643] Trial 520 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:09:34,129] Trial 521 finished with value: -0.7362373843523525 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.18797060757789585, 'lambda_l2': 0.4083061492906685, 'num_leaves': 174, 'feature_fraction': 0.14572910353129379, 'bagging_fraction': 0.9825778389213242, 'bagging_freq': 1, 'min_child_samples': 19, 'learning_rate': 8.904667931347717e-05, 'max_depth': 35, 'min_split_gain': 0.15273154092842983, 'subsample': 0.6714282285551507, 'colsample_bytree': 0.7206964872328607, 'num_iterations': 159, 'max_bin': 445, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:09:34,979] Trial 522 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:09:35,882] Trial 523 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:09:47,455] Trial 524 finished with value: -0.729848176342338 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.14544327968133736, 'lambda_l2': 1.914820922156051e-08, 'num_leaves': 371, 'feature_fraction': 0.14378356443348853, 'bagging_fraction': 0.9730730125468003, 'bagging_freq': 1, 'min_child_samples': 15, 'learning_rate': 0.0005533592375788302, 'max_depth': 34, 'min_split_gain': 0.8060553844526857, 'subsample': 0.6599914671291588, 'colsample_bytree': 0.6896976415371988, 'num_iterations': 163, 'max_bin': 133, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:09:47,906] Trial 525 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:48,519] Trial 526 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:09:49,657] Trial 527 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:09:50,397] Trial 528 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:50,926] Trial 529 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:09:51,556] Trial 530 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:52,012] Trial 531 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:09:52,709] Trial 532 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:06,273] Trial 533 finished with value: -0.7268434151855621 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.046769876945304406, 'lambda_l2': 2.834202566589532e-05, 'num_leaves': 133, 'feature_fraction': 0.13076016465565685, 'bagging_fraction': 0.9818890244991065, 'bagging_freq': 2, 'min_child_samples': 16, 'learning_rate': 0.0006328472629145867, 'max_depth': 30, 'min_split_gain': 0.2888452911752582, 'subsample': 0.6367147302721359, 'colsample_bytree': 0.7178203730575615, 'num_iterations': 200, 'max_bin': 248, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:10:06,642] Trial 534 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:07,978] Trial 535 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:10:08,382] Trial 536 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:09,334] Trial 537 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:10:09,841] Trial 538 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:25,904] Trial 539 finished with value: -0.7280505752163152 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.09320259136580127, 'lambda_l2': 7.242686951774074e-08, 'num_leaves': 163, 'feature_fraction': 0.10157893704586254, 'bagging_fraction': 0.9640784547531892, 'bagging_freq': 1, 'min_child_samples': 17, 'learning_rate': 0.0013733838560511947, 'max_depth': 32, 'min_split_gain': 0.2966289723818142, 'subsample': 0.6039662278973823, 'colsample_bytree': 0.7603843885815441, 'num_iterations': 213, 'max_bin': 176, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:10:26,600] Trial 540 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:27,779] Trial 541 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:10:28,464] Trial 542 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:29,014] Trial 543 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:29,587] Trial 544 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:30,042] Trial 545 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:30,436] Trial 546 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:30,778] Trial 547 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:31,509] Trial 548 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:10:32,204] Trial 549 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:32,735] Trial 550 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:33,099] Trial 551 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:33,672] Trial 552 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:34,326] Trial 553 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:34,887] Trial 554 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:10:35,387] Trial 555 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:10:47,763] Trial 556 finished with value: -0.7224721243088655 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.12376672144253427, 'lambda_l2': 0.0010781373206885968, 'num_leaves': 143, 'feature_fraction': 0.14962964406425175, 'bagging_fraction': 0.9606095394642149, 'bagging_freq': 3, 'min_child_samples': 19, 'learning_rate': 0.0006764089039257879, 'max_depth': 32, 'min_split_gain': 0.21217427793237817, 'subsample': 0.6263719475851023, 'colsample_bytree': 0.9713027290757282, 'num_iterations': 158, 'max_bin': 657, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:10:48,247] Trial 557 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:04,335] Trial 558 finished with value: -0.7309763818460637 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.7996694754489043, 'lambda_l2': 3.123426545088188e-08, 'num_leaves': 155, 'feature_fraction': 0.17028927433543128, 'bagging_fraction': 0.9863144519812397, 'bagging_freq': 2, 'min_child_samples': 17, 'learning_rate': 0.0008710281830380615, 'max_depth': 34, 'min_split_gain': 0.26247893725816623, 'subsample': 0.24641821431360486, 'colsample_bytree': 0.7576545417752404, 'num_iterations': 202, 'max_bin': 197, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:11:04,790] Trial 559 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:05,236] Trial 560 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:06,349] Trial 561 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:11:06,950] Trial 562 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:22,893] Trial 563 finished with value: -0.7326079971992538 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.1653824320969848, 'lambda_l2': 4.714080135940562e-06, 'num_leaves': 170, 'feature_fraction': 0.19961314702837782, 'bagging_fraction': 0.9381947160165836, 'bagging_freq': 2, 'min_child_samples': 18, 'learning_rate': 0.0008898491217537095, 'max_depth': 33, 'min_split_gain': 0.20603720704067197, 'subsample': 0.30204320809216567, 'colsample_bytree': 0.7269130801944835, 'num_iterations': 193, 'max_bin': 219, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:11:23,312] Trial 564 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:23,973] Trial 565 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:24,481] Trial 566 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:24,985] Trial 567 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:25,506] Trial 568 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:25,961] Trial 569 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:26,941] Trial 570 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:32,954] Trial 571 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:11:33,317] Trial 572 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:35,865] Trial 573 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:11:36,815] Trial 574 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:11:37,214] Trial 575 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:40,722] Trial 576 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:11:41,241] Trial 577 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:42,276] Trial 578 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:11:42,737] Trial 579 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:43,165] Trial 580 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:43,822] Trial 581 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:44,702] Trial 582 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:11:45,177] Trial 583 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:45,662] Trial 584 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:53,631] Trial 585 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:11:56,444] Trial 586 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:11:56,885] Trial 587 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:57,297] Trial 588 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:11:58,632] Trial 589 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:11:59,361] Trial 590 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:00,178] Trial 591 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:00,742] Trial 592 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:01,404] Trial 593 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:12:02,688] Trial 594 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:05,755] Trial 595 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:12:06,191] Trial 596 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:07,056] Trial 597 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:08,623] Trial 598 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:12:09,151] Trial 599 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:10,289] Trial 600 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:10,905] Trial 601 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:11,755] Trial 602 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:12,313] Trial 603 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:13,021] Trial 604 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:13,794] Trial 605 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:15,023] Trial 606 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:16,066] Trial 607 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:16,601] Trial 608 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:17,055] Trial 609 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:17,887] Trial 610 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:25,184] Trial 611 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:12:25,827] Trial 612 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:26,471] Trial 613 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:27,336] Trial 614 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:28,167] Trial 615 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:42,698] Trial 616 finished with value: -0.7263774707666437 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.7739259942868268e-08, 'lambda_l2': 0.5811327727439668, 'num_leaves': 386, 'feature_fraction': 0.14891150268935832, 'bagging_fraction': 0.9461280582210051, 'bagging_freq': 4, 'min_child_samples': 23, 'learning_rate': 0.0002357894105317619, 'max_depth': 35, 'min_split_gain': 0.21106105904067343, 'subsample': 0.6013411734792392, 'colsample_bytree': 0.6832393533355015, 'num_iterations': 191, 'max_bin': 515, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:12:43,817] Trial 617 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:12:44,963] Trial 618 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:45,792] Trial 619 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:46,673] Trial 620 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:48,510] Trial 621 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:12:49,228] Trial 622 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:50,321] Trial 623 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:12:51,067] Trial 624 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:12:59,732] Trial 625 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:13:01,536] Trial 626 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:13:02,414] Trial 627 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:03,170] Trial 628 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:13:04,851] Trial 629 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:13:05,425] Trial 630 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:07,905] Trial 631 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:13:08,625] Trial 632 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:13:09,603] Trial 633 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:10,458] Trial 634 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:13:15,846] Trial 635 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:13:16,255] Trial 636 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:17,222] Trial 637 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:18,245] Trial 638 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:13:18,889] Trial 639 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:19,604] Trial 640 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:20,619] Trial 641 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:13:21,269] Trial 642 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:13:21,967] Trial 643 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:13:24,505] Trial 644 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:14:41,075] Trial 645 finished with value: -0.7304177405154682 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.7234313461142923e-08, 'lambda_l2': 0.35164072414657527, 'num_leaves': 427, 'feature_fraction': 0.14468752596204318, 'bagging_fraction': 0.9140966640279948, 'bagging_freq': 2, 'min_child_samples': 20, 'learning_rate': 0.0007071809125110487, 'max_depth': 32, 'min_split_gain': 0.24688557031401404, 'subsample': 0.6262549613956734, 'colsample_bytree': 0.6674576326196839, 'num_iterations': 966, 'max_bin': 163, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:14:41,794] Trial 646 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:42,714] Trial 647 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:43,615] Trial 648 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:44,627] Trial 649 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:14:45,483] Trial 650 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:46,330] Trial 651 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:47,335] Trial 652 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:48,855] Trial 653 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:14:49,514] Trial 654 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:50,440] Trial 655 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:14:51,176] Trial 656 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:14:52,504] Trial 657 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:14:53,069] Trial 658 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:16:09,395] Trial 659 finished with value: -0.7232749327283984 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 5.628030987936496e-08, 'lambda_l2': 0.40615674734869905, 'num_leaves': 151, 'feature_fraction': 0.11610112338337873, 'bagging_fraction': 0.9476021887607037, 'bagging_freq': 2, 'min_child_samples': 21, 'learning_rate': 0.0005522904866022729, 'max_depth': 35, 'min_split_gain': 0.2992823614158891, 'subsample': 0.6530995674144027, 'colsample_bytree': 0.5117934125284432, 'num_iterations': 993, 'max_bin': 475, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:16:10,241] Trial 660 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:16:17,611] Trial 661 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:16:33,424] Trial 662 finished with value: -0.7242169674402763 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.77158829366981e-07, 'lambda_l2': 0.6759667630940978, 'num_leaves': 382, 'feature_fraction': 0.13391361156844062, 'bagging_fraction': 0.9183242796651817, 'bagging_freq': 4, 'min_child_samples': 23, 'learning_rate': 0.0008126677072582204, 'max_depth': 35, 'min_split_gain': 0.2005861657461549, 'subsample': 0.29070747278895637, 'colsample_bytree': 0.6276271642847489, 'num_iterations': 179, 'max_bin': 825, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:16:34,122] Trial 663 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:16:34,996] Trial 664 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:38,293] Trial 665 finished with value: -0.7348267416515297 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.4862555464143065e-08, 'lambda_l2': 0.3540230300034963, 'num_leaves': 163, 'feature_fraction': 0.13418664012206696, 'bagging_fraction': 0.9990494926637451, 'bagging_freq': 1, 'min_child_samples': 18, 'learning_rate': 0.0005034380117302099, 'max_depth': 33, 'min_split_gain': 0.25491302711689395, 'subsample': 0.5919175935570468, 'colsample_bytree': 0.6966750926318107, 'num_iterations': 774, 'max_bin': 190, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:17:38,737] Trial 666 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:39,332] Trial 667 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:17:39,820] Trial 668 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:40,304] Trial 669 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:17:40,807] Trial 670 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:42,395] Trial 671 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:17:44,317] Trial 672 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:17:44,863] Trial 673 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:45,341] Trial 674 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:46,884] Trial 675 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:17:47,552] Trial 676 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:48,564] Trial 677 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:17:51,170] Trial 678 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:17:52,049] Trial 679 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:17:53,975] Trial 680 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:17:54,610] Trial 681 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:18:41,432] Trial 682 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:18:42,748] Trial 683 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:18:43,348] Trial 684 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:18:45,516] Trial 685 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:18:46,485] Trial 686 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:18:47,343] Trial 687 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:02,473] Trial 688 finished with value: -0.7274067291921107 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 6.096911577911492e-08, 'lambda_l2': 1.4962116336015703e-07, 'num_leaves': 428, 'feature_fraction': 0.17457722463699255, 'bagging_fraction': 0.9592697235479959, 'bagging_freq': 4, 'min_child_samples': 23, 'learning_rate': 0.0005196369303877396, 'max_depth': 35, 'min_split_gain': 0.2221960311407578, 'subsample': 0.6600488353886516, 'colsample_bytree': 0.7289741168348269, 'num_iterations': 194, 'max_bin': 116, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:19:15,192] Trial 689 finished with value: -0.7242393302401253 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 5.743469481785177e-08, 'lambda_l2': 4.525289066727023e-07, 'num_leaves': 440, 'feature_fraction': 0.16768368024694377, 'bagging_fraction': 0.9683817091259104, 'bagging_freq': 4, 'min_child_samples': 24, 'learning_rate': 0.0006660608111514774, 'max_depth': 31, 'min_split_gain': 0.1701787731082635, 'subsample': 0.6604275386746483, 'colsample_bytree': 0.7230245473153045, 'num_iterations': 170, 'max_bin': 121, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:19:15,973] Trial 690 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:16,913] Trial 691 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:20,443] Trial 692 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:19:21,147] Trial 693 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:22,034] Trial 694 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:23,114] Trial 695 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:24,236] Trial 696 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:19:25,025] Trial 697 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:25,437] Trial 698 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:26,895] Trial 699 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:19:28,362] Trial 700 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:19:29,360] Trial 701 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:30,191] Trial 702 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:31,409] Trial 703 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:19:32,135] Trial 704 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:32,952] Trial 705 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:33,600] Trial 706 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:34,225] Trial 707 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:34,737] Trial 708 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:35,233] Trial 709 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:36,002] Trial 710 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:36,998] Trial 711 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:49,540] Trial 712 finished with value: -0.722745815543057 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.19360219865208053, 'lambda_l2': 1.5575845695632283e-07, 'num_leaves': 155, 'feature_fraction': 0.13267314654987566, 'bagging_fraction': 0.9826361222262513, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.0005463755444531359, 'max_depth': 34, 'min_split_gain': 0.11147969332204535, 'subsample': 0.6277691193570226, 'colsample_bytree': 0.7278993656200846, 'num_iterations': 163, 'max_bin': 142, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:19:50,499] Trial 713 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:19:51,069] Trial 714 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:52,117] Trial 715 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:19:52,865] Trial 716 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:53,733] Trial 717 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:54,581] Trial 718 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:19:55,346] Trial 719 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:01,967] Trial 720 finished with value: -0.7289737463839685 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 8.64648452631066e-08, 'lambda_l2': 0.7531511612761077, 'num_leaves': 393, 'feature_fraction': 0.1543604346517286, 'bagging_fraction': 0.9822153573353993, 'bagging_freq': 4, 'min_child_samples': 16, 'learning_rate': 0.0010245024722765844, 'max_depth': 35, 'min_split_gain': 0.5644718905554837, 'subsample': 0.5945117879799318, 'colsample_bytree': 0.7149119510836308, 'num_iterations': 774, 'max_bin': 184, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:21:02,631] Trial 721 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:03,447] Trial 722 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:04,261] Trial 723 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:04,710] Trial 724 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:05,494] Trial 725 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:06,400] Trial 726 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:07,431] Trial 727 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:21:07,860] Trial 728 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:08,557] Trial 729 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:09,636] Trial 730 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:10,704] Trial 731 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:12,096] Trial 732 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:21:12,578] Trial 733 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:13,300] Trial 734 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:21:13,982] Trial 735 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:14,702] Trial 736 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:20,493] Trial 737 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:21:24,272] Trial 738 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:21:24,951] Trial 739 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:25,801] Trial 740 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:26,342] Trial 741 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:27,113] Trial 742 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:29,169] Trial 743 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:21:34,274] Trial 744 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:21:35,109] Trial 745 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:36,065] Trial 746 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:36,845] Trial 747 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:37,976] Trial 748 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:21:40,306] Trial 749 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:21:40,996] Trial 750 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:21:55,119] Trial 751 finished with value: -0.7250305977813312 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.6738666744647874e-08, 'lambda_l2': 0.5341753656867314, 'num_leaves': 156, 'feature_fraction': 0.18358869394138144, 'bagging_fraction': 0.9305671760744468, 'bagging_freq': 2, 'min_child_samples': 19, 'learning_rate': 0.0006015785046229215, 'max_depth': 34, 'min_split_gain': 0.423763220593679, 'subsample': 0.3524692675927224, 'colsample_bytree': 0.6769703747563379, 'num_iterations': 186, 'max_bin': 193, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:21:56,040] Trial 752 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:56,548] Trial 753 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:21:57,377] Trial 754 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:21:58,958] Trial 755 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:21:59,763] Trial 756 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:15,681] Trial 757 finished with value: -0.7335477334699894 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.10279741638953259, 'lambda_l2': 0.8122787721756822, 'num_leaves': 396, 'feature_fraction': 0.13144341470373344, 'bagging_fraction': 0.9818966928302486, 'bagging_freq': 4, 'min_child_samples': 20, 'learning_rate': 0.000726807881030043, 'max_depth': 32, 'min_split_gain': 0.17835521213394046, 'subsample': 0.7282627075397653, 'colsample_bytree': 0.7752915138461074, 'num_iterations': 168, 'max_bin': 525, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:22:16,617] Trial 758 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:17,072] Trial 759 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:17,774] Trial 760 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:19,033] Trial 761 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:22:20,571] Trial 762 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:22:21,173] Trial 763 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:24,131] Trial 764 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:22:25,057] Trial 765 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:26,649] Trial 766 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:22:29,593] Trial 767 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:22:30,379] Trial 768 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:32,393] Trial 769 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:22:33,063] Trial 770 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:33,609] Trial 771 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:34,327] Trial 772 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:35,529] Trial 773 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:22:36,107] Trial 774 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:36,721] Trial 775 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:37,828] Trial 776 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:22:38,591] Trial 777 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:39,317] Trial 778 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:41,662] Trial 779 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:22:42,725] Trial 780 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:22:43,492] Trial 781 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:44,355] Trial 782 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:22:45,013] Trial 783 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:45,849] Trial 784 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:46,751] Trial 785 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:48,019] Trial 786 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:22:51,385] Trial 787 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:22:51,927] Trial 788 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:22:57,531] Trial 789 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:22:58,320] Trial 790 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:10,430] Trial 791 finished with value: -0.7257649332184175 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 4.5967155243094655e-08, 'lambda_l2': 0.1569336968860688, 'num_leaves': 143, 'feature_fraction': 0.16073077479880404, 'bagging_fraction': 0.9822275329312835, 'bagging_freq': 2, 'min_child_samples': 21, 'learning_rate': 0.000335476633143842, 'max_depth': 17, 'min_split_gain': 0.3123404155356042, 'subsample': 0.6606505782343256, 'colsample_bytree': 0.6274786303992597, 'num_iterations': 163, 'max_bin': 508, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:23:11,272] Trial 792 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:23:16,726] Trial 793 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:23:17,830] Trial 794 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:23:18,825] Trial 795 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:20,251] Trial 796 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:23:21,114] Trial 797 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:23:22,096] Trial 798 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:23:30,445] Trial 799 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:23:31,187] Trial 800 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:31,957] Trial 801 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:32,826] Trial 802 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:23:33,386] Trial 803 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:33,876] Trial 804 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:34,431] Trial 805 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:23:36,471] Trial 806 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:24:24,188] Trial 807 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:24:25,091] Trial 808 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:25,800] Trial 809 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:28,167] Trial 810 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:24:29,323] Trial 811 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:24:31,337] Trial 812 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:24:31,950] Trial 813 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:32,544] Trial 814 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:33,127] Trial 815 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:24:35,133] Trial 816 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:24:36,418] Trial 817 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:37,914] Trial 818 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:24:38,569] Trial 819 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:39,268] Trial 820 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:24:40,427] Trial 821 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:24:41,539] Trial 822 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:24:42,343] Trial 823 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:24:43,362] Trial 824 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:25:39,444] Trial 825 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:25:41,101] Trial 826 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:25:42,418] Trial 827 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:25:43,609] Trial 828 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:25:44,671] Trial 829 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:25:46,201] Trial 830 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:25:48,520] Trial 831 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:25:54,498] Trial 832 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:25:55,008] Trial 833 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:25:55,839] Trial 834 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:25:57,090] Trial 835 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:26:24,570] Trial 836 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:26:25,219] Trial 837 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:27:15,737] Trial 838 finished with value: -0.730414281059237 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 5.4977164816256226e-08, 'lambda_l2': 7.284767774754117e-08, 'num_leaves': 381, 'feature_fraction': 0.13201697087326467, 'bagging_fraction': 0.9995234253790618, 'bagging_freq': 10, 'min_child_samples': 22, 'learning_rate': 0.0009417437076004363, 'max_depth': 32, 'min_split_gain': 0.24016223490017075, 'subsample': 0.6347753245628116, 'colsample_bytree': 0.7105650208499915, 'num_iterations': 709, 'max_bin': 99, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:27:16,321] Trial 839 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:16,805] Trial 840 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:22,581] Trial 841 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:27:23,162] Trial 842 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:27:24,133] Trial 843 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:27:24,765] Trial 844 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:25,448] Trial 845 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:26,175] Trial 846 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:26,838] Trial 847 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:27:27,273] Trial 848 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:28,132] Trial 849 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:27:28,828] Trial 850 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:29,596] Trial 851 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:30,393] Trial 852 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:27:31,105] Trial 853 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:27:31,860] Trial 854 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:27:32,949] Trial 855 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:28:16,786] Trial 856 finished with value: -0.7250824289950983 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.17540609666339954, 'lambda_l2': 1.2808020266650069e-08, 'num_leaves': 269, 'feature_fraction': 0.15325574818554075, 'bagging_fraction': 0.9720591826629486, 'bagging_freq': 10, 'min_child_samples': 23, 'learning_rate': 0.000527387322838932, 'max_depth': 32, 'min_split_gain': 0.1762099277625394, 'subsample': 0.6636942200216951, 'colsample_bytree': 0.7700425381162596, 'num_iterations': 637, 'max_bin': 132, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:28:17,562] Trial 857 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:28:53,200] Trial 858 finished with value: -0.7300170382824251 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.05506216700740485, 'lambda_l2': 1.8376930227427, 'num_leaves': 213, 'feature_fraction': 0.20533677826757274, 'bagging_fraction': 0.9995792508772933, 'bagging_freq': 10, 'min_child_samples': 21, 'learning_rate': 3.49021562498249e-05, 'max_depth': 33, 'min_split_gain': 0.25073918550841784, 'subsample': 0.2297410817374694, 'colsample_bytree': 0.7954306560530884, 'num_iterations': 506, 'max_bin': 93, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:28:53,766] Trial 859 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:28:54,797] Trial 860 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:28:55,409] Trial 861 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:28:55,896] Trial 862 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:28:57,228] Trial 863 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:28:57,831] Trial 864 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:34,841] Trial 865 finished with value: -0.722025090346497 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.7127741477930517, 'lambda_l2': 5.6521094210850125, 'num_leaves': 202, 'feature_fraction': 0.19754610070462691, 'bagging_fraction': 0.9528584890643567, 'bagging_freq': 10, 'min_child_samples': 17, 'learning_rate': 2.9652995866364237e-05, 'max_depth': 33, 'min_split_gain': 0.24811655328907756, 'subsample': 0.17489260072358742, 'colsample_bytree': 0.7737409222144184, 'num_iterations': 549, 'max_bin': 115, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:29:35,209] Trial 866 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:35,721] Trial 867 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:29:36,507] Trial 868 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:29:37,018] Trial 869 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:37,401] Trial 870 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:42,194] Trial 871 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:29:43,514] Trial 872 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:29:43,984] Trial 873 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:44,414] Trial 874 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:45,160] Trial 875 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:47,558] Trial 876 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:29:48,305] Trial 877 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:29:49,327] Trial 878 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:29:51,603] Trial 879 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:29:52,190] Trial 880 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:29:52,898] Trial 881 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:02,104] Trial 882 finished with value: -0.7256880370629284 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.08245830136609332, 'lambda_l2': 2.2234568073314718e-05, 'num_leaves': 165, 'feature_fraction': 0.11712094441972895, 'bagging_fraction': 0.9831975518042637, 'bagging_freq': 3, 'min_child_samples': 20, 'learning_rate': 5.853664441641293e-05, 'max_depth': 29, 'min_split_gain': 0.16530161238039062, 'subsample': 0.3770452444744305, 'colsample_bytree': 0.6899170222537649, 'num_iterations': 124, 'max_bin': 214, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:30:02,826] Trial 883 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:03,359] Trial 884 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:04,050] Trial 885 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:05,287] Trial 886 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:05,996] Trial 887 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:06,726] Trial 888 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:07,814] Trial 889 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:10,007] Trial 890 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:30:10,600] Trial 891 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:11,424] Trial 892 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:12,296] Trial 893 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:13,880] Trial 894 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:14,422] Trial 895 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:15,059] Trial 896 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:17,183] Trial 897 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:30:17,807] Trial 898 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:19,330] Trial 899 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:20,451] Trial 900 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:21,121] Trial 901 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:21,632] Trial 902 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:22,208] Trial 903 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:22,911] Trial 904 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:36,278] Trial 905 finished with value: -0.7247581233249033 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.7501807726302977e-07, 'lambda_l2': 2.82305716610574e-08, 'num_leaves': 387, 'feature_fraction': 0.1177357236089531, 'bagging_fraction': 0.9824465700321483, 'bagging_freq': 4, 'min_child_samples': 22, 'learning_rate': 0.0006311544574607817, 'max_depth': 35, 'min_split_gain': 0.13757139283480918, 'subsample': 0.5444431411957337, 'colsample_bytree': 0.6896089649767988, 'num_iterations': 178, 'max_bin': 127, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:30:37,039] Trial 906 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:37,824] Trial 907 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:38,601] Trial 908 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:39,070] Trial 909 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:40,344] Trial 910 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:41,235] Trial 911 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:46,978] Trial 912 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:30:47,735] Trial 913 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:48,358] Trial 914 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:49,110] Trial 915 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:50,125] Trial 916 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:50,861] Trial 917 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:51,515] Trial 918 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:52,341] Trial 919 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:53,275] Trial 920 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:54,580] Trial 921 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:55,766] Trial 922 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:30:56,199] Trial 923 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:30:56,753] Trial 924 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:30:58,611] Trial 925 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:30:59,291] Trial 926 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:18,319] Trial 927 finished with value: -0.731863884153273 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.36240166337311e-08, 'lambda_l2': 0.975839507153845, 'num_leaves': 401, 'feature_fraction': 0.16423020902870958, 'bagging_fraction': 0.9563891408522175, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.0007014225469707834, 'max_depth': 35, 'min_split_gain': 0.2559677424066925, 'subsample': 0.36206817843956246, 'colsample_bytree': 0.7984044108201136, 'num_iterations': 228, 'max_bin': 224, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:31:18,887] Trial 928 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:21,247] Trial 929 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:31:22,709] Trial 930 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:31:23,637] Trial 931 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:24,549] Trial 932 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:31:30,983] Trial 933 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:31:39,129] Trial 934 finished with value: -0.7266302403353604 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 4.25292708973669e-08, 'lambda_l2': 1.4926464377230284, 'num_leaves': 392, 'feature_fraction': 0.19683301074533813, 'bagging_fraction': 0.9556344536008229, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.2838591159782048, 'max_depth': 35, 'min_split_gain': 0.18439237774533335, 'subsample': 0.3395943278508511, 'colsample_bytree': 0.8242659213632914, 'num_iterations': 109, 'max_bin': 85, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:31:40,350] Trial 935 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:31:41,490] Trial 936 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:42,322] Trial 937 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:43,094] Trial 938 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:45,218] Trial 939 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:31:46,181] Trial 940 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:47,053] Trial 941 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:31:49,651] Trial 942 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:31:50,376] Trial 943 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:31:50,736] Trial 944 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:31:51,408] Trial 945 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:31:52,192] Trial 946 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:31:54,413] Trial 947 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:32:00,273] Trial 948 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:32:00,941] Trial 949 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:32:01,821] Trial 950 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:32:02,763] Trial 951 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:32:03,592] Trial 952 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:32:06,717] Trial 953 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:32:07,695] Trial 954 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:32:08,688] Trial 955 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:32:15,383] Trial 956 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:32:16,120] Trial 957 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:32:17,444] Trial 958 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:32:18,655] Trial 959 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:32:21,659] Trial 960 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:32:22,550] Trial 961 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:32:30,013] Trial 962 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:32:44,459] Trial 963 finished with value: -0.7242494963471305 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.481732618162078e-07, 'lambda_l2': 0.25623483294987986, 'num_leaves': 410, 'feature_fraction': 0.1267190424331034, 'bagging_fraction': 0.9594617972266141, 'bagging_freq': 3, 'min_child_samples': 20, 'learning_rate': 0.00027188020980534937, 'max_depth': 23, 'min_split_gain': 0.21990967036234235, 'subsample': 0.7873311565811609, 'colsample_bytree': 0.8414398977208591, 'num_iterations': 167, 'max_bin': 432, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:32:45,093] Trial 964 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:32:45,847] Trial 965 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:32:46,779] Trial 966 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:32:47,533] Trial 967 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:33:25,563] Trial 968 finished with value: -0.7343979265379006 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.6069614979336232e-08, 'lambda_l2': 1.6696572228847542, 'num_leaves': 351, 'feature_fraction': 0.1328619885692503, 'bagging_fraction': 0.9998816851521733, 'bagging_freq': 4, 'min_child_samples': 19, 'learning_rate': 0.00034065507995260664, 'max_depth': 34, 'min_split_gain': 0.40245361811452035, 'subsample': 0.6022675772301803, 'colsample_bytree': 0.5008904918538023, 'num_iterations': 483, 'max_bin': 492, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:33:32,006] Trial 969 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:33:32,822] Trial 970 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:33:34,831] Trial 971 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:33:36,025] Trial 972 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:33:37,366] Trial 973 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:33:38,548] Trial 974 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:33:39,366] Trial 975 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:33:40,035] Trial 976 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:33:40,852] Trial 977 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:33:41,568] Trial 978 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:33:42,722] Trial 979 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:33:43,251] Trial 980 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:33:43,989] Trial 981 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:34:12,673] Trial 982 finished with value: -0.730364676595554 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.216333982722003e-08, 'lambda_l2': 1.8614254636393488, 'num_leaves': 397, 'feature_fraction': 0.1294563141992208, 'bagging_fraction': 0.9601485921846521, 'bagging_freq': 3, 'min_child_samples': 20, 'learning_rate': 0.00044971929231470294, 'max_depth': 37, 'min_split_gain': 0.45173864106661854, 'subsample': 0.5205951149780201, 'colsample_bytree': 0.6582455198593474, 'num_iterations': 449, 'max_bin': 113, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:34:13,846] Trial 983 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:34:14,603] Trial 984 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:34:15,858] Trial 985 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:34:16,580] Trial 986 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:34:49,323] Trial 987 finished with value: -0.7300890539309581 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.0542676996209903e-08, 'lambda_l2': 1.4568377038333717, 'num_leaves': 389, 'feature_fraction': 0.10172883281185371, 'bagging_fraction': 0.9999993969595522, 'bagging_freq': 3, 'min_child_samples': 19, 'learning_rate': 0.0003264932537557417, 'max_depth': 37, 'min_split_gain': 0.5071249453053567, 'subsample': 0.5362373040786115, 'colsample_bytree': 0.6096275483520538, 'num_iterations': 490, 'max_bin': 122, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:34:49,975] Trial 988 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:34:50,607] Trial 989 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:34:51,327] Trial 990 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:34:52,023] Trial 991 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:34:58,443] Trial 992 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:34:59,046] Trial 993 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:35:01,048] Trial 994 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:35:01,780] Trial 995 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:35:34,017] Trial 996 finished with value: -0.7269437025423859 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.2622358029018526e-08, 'lambda_l2': 1.8787449056033827, 'num_leaves': 357, 'feature_fraction': 0.10006618831986416, 'bagging_fraction': 0.9703184051660707, 'bagging_freq': 3, 'min_child_samples': 18, 'learning_rate': 0.00025988074127716247, 'max_depth': 39, 'min_split_gain': 0.5133255990675739, 'subsample': 0.5773093648028378, 'colsample_bytree': 0.6478636596248627, 'num_iterations': 485, 'max_bin': 95, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:35:34,547] Trial 997 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:35:40,434] Trial 998 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:35:42,679] Trial 999 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:35:44,767] Trial 1000 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:35:45,628] Trial 1001 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:35:46,409] Trial 1002 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:35:48,902] Trial 1003 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:35:49,675] Trial 1004 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:35:50,561] Trial 1005 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:35:56,440] Trial 1006 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:35:57,133] Trial 1007 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:35:57,792] Trial 1008 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:02,786] Trial 1009 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:36:05,246] Trial 1010 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:36:06,074] Trial 1011 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:06,452] Trial 1012 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:07,178] Trial 1013 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:36:07,708] Trial 1014 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:36:08,289] Trial 1015 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:36:09,670] Trial 1016 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:36:10,704] Trial 1017 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:36:11,549] Trial 1018 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:12,399] Trial 1019 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:13,066] Trial 1020 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:13,848] Trial 1021 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:14,567] Trial 1022 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:15,276] Trial 1023 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:15,767] Trial 1024 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:16,847] Trial 1025 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:36:17,402] Trial 1026 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:18,135] Trial 1027 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:36:19,372] Trial 1028 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:36:56,032] Trial 1029 finished with value: -0.7338053821265439 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 5.6319891447059773e-08, 'lambda_l2': 2.9261006393023286e-08, 'num_leaves': 438, 'feature_fraction': 0.13032557620263843, 'bagging_fraction': 0.9999352862792944, 'bagging_freq': 1, 'min_child_samples': 19, 'learning_rate': 0.00849657641558624, 'max_depth': 34, 'min_split_gain': 0.5562684351957222, 'subsample': 0.593106887394881, 'colsample_bytree': 0.6793777389278566, 'num_iterations': 482, 'max_bin': 221, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:36:59,785] Trial 1030 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:37:00,702] Trial 1031 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:37:01,640] Trial 1032 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:37:02,435] Trial 1033 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:37:02,802] Trial 1034 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:37:03,494] Trial 1035 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:37:20,698] Trial 1036 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:37:41,622] Trial 1037 finished with value: -0.7289153686281793 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.381544146342661, 'lambda_l2': 3.674372442307759e-08, 'num_leaves': 160, 'feature_fraction': 0.11541213139905637, 'bagging_fraction': 0.9995149306347401, 'bagging_freq': 1, 'min_child_samples': 19, 'learning_rate': 0.003594276711932508, 'max_depth': 32, 'min_split_gain': 0.5001764261775102, 'subsample': 0.5933600633414546, 'colsample_bytree': 0.6876557776451209, 'num_iterations': 305, 'max_bin': 248, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:37:42,297] Trial 1038 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:37:43,054] Trial 1039 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:37:43,780] Trial 1040 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:01,645] Trial 1041 finished with value: -0.7281637022398462 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.5026432939780834, 'lambda_l2': 1.535966339437433e-08, 'num_leaves': 387, 'feature_fraction': 0.12816179651750828, 'bagging_fraction': 0.9984508587208394, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.004651582493114989, 'max_depth': 15, 'min_split_gain': 0.47661649127257594, 'subsample': 0.5354462941086713, 'colsample_bytree': 0.6879924176587859, 'num_iterations': 283, 'max_bin': 225, 'seed': 1338}. Best is trial 521 with value: -0.7362373843523525.\n",
      "[I 2024-06-13 15:38:02,340] Trial 1042 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:03,132] Trial 1043 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:03,692] Trial 1044 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:04,430] Trial 1045 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:05,346] Trial 1046 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:06,053] Trial 1047 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:06,823] Trial 1048 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:12,139] Trial 1049 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:38:13,054] Trial 1050 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:13,964] Trial 1051 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:14,974] Trial 1052 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:15,637] Trial 1053 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:16,160] Trial 1054 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:21,549] Trial 1055 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:38:22,454] Trial 1056 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:23,407] Trial 1057 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:25,715] Trial 1058 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:38:26,592] Trial 1059 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:43,127] Trial 1060 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:38:48,360] Trial 1061 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:38:49,256] Trial 1062 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:51,318] Trial 1063 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:38:52,111] Trial 1064 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:53,222] Trial 1065 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:38:53,970] Trial 1066 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:54,764] Trial 1067 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:38:55,693] Trial 1068 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:38:56,786] Trial 1069 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:38:58,198] Trial 1070 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:38:59,010] Trial 1071 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:39:01,046] Trial 1072 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:39:02,039] Trial 1073 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:39:02,628] Trial 1074 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:39:03,893] Trial 1075 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:39:05,251] Trial 1076 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:39:05,982] Trial 1077 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:39:06,800] Trial 1078 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:39:07,493] Trial 1079 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:39:08,385] Trial 1080 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:39:10,360] Trial 1081 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:39:11,204] Trial 1082 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:39:12,773] Trial 1083 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:39:15,194] Trial 1084 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:39:16,236] Trial 1085 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:40:08,109] Trial 1086 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:40:09,840] Trial 1087 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:40:10,576] Trial 1088 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:11,702] Trial 1089 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:40:12,604] Trial 1090 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:40:13,256] Trial 1091 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:40:13,788] Trial 1092 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:40:14,498] Trial 1093 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:15,229] Trial 1094 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:16,191] Trial 1095 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:40:17,268] Trial 1096 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:40:18,009] Trial 1097 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:23,285] Trial 1098 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:40:24,017] Trial 1099 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:25,078] Trial 1100 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:40:25,643] Trial 1101 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:26,678] Trial 1102 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:40:27,558] Trial 1103 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:40:56,339] Trial 1104 finished with value: -0.7398982304741816 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 0.3696382217904096, 'lambda_l2': 0.5711791321324636, 'num_leaves': 200, 'feature_fraction': 0.1293466697652961, 'bagging_fraction': 0.9999123047800127, 'bagging_freq': 2, 'min_child_samples': 18, 'learning_rate': 0.3283516656493199, 'max_depth': 34, 'min_split_gain': 0.12723998035309758, 'subsample': 0.5329473808512917, 'colsample_bytree': 0.739906911174512, 'num_iterations': 343, 'max_bin': 147, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:40:56,841] Trial 1105 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:57,331] Trial 1106 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:57,869] Trial 1107 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:58,399] Trial 1108 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:58,913] Trial 1109 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:40:59,565] Trial 1110 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:41:00,060] Trial 1111 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:00,535] Trial 1112 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:01,015] Trial 1113 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:01,545] Trial 1114 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:02,050] Trial 1115 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:02,527] Trial 1116 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:03,081] Trial 1117 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:03,556] Trial 1118 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:04,056] Trial 1119 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:04,566] Trial 1120 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:05,605] Trial 1121 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:41:06,056] Trial 1122 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:06,862] Trial 1123 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:41:09,065] Trial 1124 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:41:09,710] Trial 1125 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:11,120] Trial 1126 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:41:43,230] Trial 1127 finished with value: -0.7264816411175772 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.2100047043501314, 'lambda_l2': 0.6402092781290734, 'num_leaves': 210, 'feature_fraction': 0.14281115971766117, 'bagging_fraction': 0.9680428120205299, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.000577114535947545, 'max_depth': 33, 'min_split_gain': 0.10954547461669271, 'subsample': 0.652474379779262, 'colsample_bytree': 0.7293928169400802, 'num_iterations': 520, 'max_bin': 104, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:41:43,951] Trial 1128 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:45,162] Trial 1129 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:41:46,002] Trial 1130 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:41:46,716] Trial 1131 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:48,294] Trial 1132 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:41:48,853] Trial 1133 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:49,668] Trial 1134 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:50,678] Trial 1135 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:51,560] Trial 1136 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:41:52,568] Trial 1137 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:41:53,400] Trial 1138 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:41:56,343] Trial 1139 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:41:58,712] Trial 1140 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:41:59,517] Trial 1141 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:42:00,324] Trial 1142 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:01,160] Trial 1143 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:02,898] Trial 1144 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:42:03,666] Trial 1145 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:04,794] Trial 1146 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:42:05,526] Trial 1147 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:06,271] Trial 1148 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:42:12,247] Trial 1149 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:42:13,015] Trial 1150 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:13,665] Trial 1151 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:14,325] Trial 1152 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:16,672] Trial 1153 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:42:17,340] Trial 1154 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:17,751] Trial 1155 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:18,361] Trial 1156 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:42:19,115] Trial 1157 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:19,702] Trial 1158 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:20,537] Trial 1159 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:21,348] Trial 1160 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:24,325] Trial 1161 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:42:25,282] Trial 1162 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:42:33,616] Trial 1163 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:42:39,075] Trial 1164 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:42:39,932] Trial 1165 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:41,004] Trial 1166 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:42:41,962] Trial 1167 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:42:42,952] Trial 1168 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:43:51,771] Trial 1169 finished with value: -0.7324384586972403 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.6980070804533596e-07, 'lambda_l2': 2.1130657982768166e-08, 'num_leaves': 208, 'feature_fraction': 0.13340145769194756, 'bagging_fraction': 0.9999451865122309, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.00037527162677616644, 'max_depth': 33, 'min_split_gain': 0.19209354980139157, 'subsample': 0.5626085020969638, 'colsample_bytree': 0.7873726424841191, 'num_iterations': 849, 'max_bin': 345, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:43:52,821] Trial 1170 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:43:53,481] Trial 1171 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:43:55,656] Trial 1172 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:43:56,229] Trial 1173 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:43:56,942] Trial 1174 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:44:48,960] Trial 1175 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:44:49,627] Trial 1176 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:46:01,205] Trial 1177 finished with value: -0.7321200332153734 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.1199481615160439e-07, 'lambda_l2': 1.2444699197840759e-08, 'num_leaves': 201, 'feature_fraction': 0.13809508985624813, 'bagging_fraction': 0.9847928876964903, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.0011302103663412507, 'max_depth': 31, 'min_split_gain': 0.18741992922561493, 'subsample': 0.5824855859793479, 'colsample_bytree': 0.53052110272422, 'num_iterations': 842, 'max_bin': 266, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:46:02,195] Trial 1178 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:46:02,704] Trial 1179 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:46:03,827] Trial 1180 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:46:04,327] Trial 1181 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:47:14,801] Trial 1182 finished with value: -0.7362569085923455 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.2829871921055226e-07, 'lambda_l2': 2.0469399443957653e-08, 'num_leaves': 225, 'feature_fraction': 0.14873499233446744, 'bagging_fraction': 0.9997366239812878, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.001014791801648181, 'max_depth': 29, 'min_split_gain': 0.1985276927610865, 'subsample': 0.5859071212090294, 'colsample_bytree': 0.5618795708152847, 'num_iterations': 859, 'max_bin': 413, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:47:16,866] Trial 1183 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:47:17,595] Trial 1184 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:48:07,111] Trial 1185 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:48:07,806] Trial 1186 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:48:08,358] Trial 1187 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:09,047] Trial 1188 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:48:09,619] Trial 1189 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:10,679] Trial 1190 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:48:11,885] Trial 1191 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:48:13,878] Trial 1192 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:48:21,715] Trial 1193 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:48:22,287] Trial 1194 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:22,869] Trial 1195 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:23,449] Trial 1196 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:24,509] Trial 1197 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:48:25,060] Trial 1198 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:25,615] Trial 1199 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:26,544] Trial 1200 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:48:27,116] Trial 1201 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:27,602] Trial 1202 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:48:28,188] Trial 1203 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:49:39,808] Trial 1204 finished with value: -0.7358598265165858 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.86705867239836e-07, 'lambda_l2': 1.6261128379159777e-08, 'num_leaves': 186, 'feature_fraction': 0.14159094695824628, 'bagging_fraction': 0.9995982658928827, 'bagging_freq': 1, 'min_child_samples': 19, 'learning_rate': 0.000358898695961427, 'max_depth': 30, 'min_split_gain': 0.13921993283985468, 'subsample': 0.5396665412468065, 'colsample_bytree': 0.5791938313009047, 'num_iterations': 847, 'max_bin': 362, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:49:40,367] Trial 1205 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:49:41,070] Trial 1206 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:49:47,823] Trial 1207 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:49:48,610] Trial 1208 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:51:05,922] Trial 1209 finished with value: -0.7342731919317804 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.0393802458089706e-07, 'lambda_l2': 1.025536601217665e-08, 'num_leaves': 185, 'feature_fraction': 0.17028713400055998, 'bagging_fraction': 0.9997755501280932, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.0010790468985135192, 'max_depth': 30, 'min_split_gain': 0.10629972329722048, 'subsample': 0.5342054407096337, 'colsample_bytree': 0.5675357584904722, 'num_iterations': 906, 'max_bin': 373, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:51:22,423] Trial 1210 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:51:22,967] Trial 1211 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:51:23,399] Trial 1212 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:51:26,144] Trial 1213 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:51:27,450] Trial 1214 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:51:27,984] Trial 1215 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:51:28,685] Trial 1216 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:51:29,273] Trial 1217 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:51:31,645] Trial 1218 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:52:30,240] Trial 1219 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:52:31,077] Trial 1220 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:31,620] Trial 1221 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:32,204] Trial 1222 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:52:32,915] Trial 1223 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:33,424] Trial 1224 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:34,005] Trial 1225 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:52:34,533] Trial 1226 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:52:35,210] Trial 1227 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:35,770] Trial 1228 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:52:36,323] Trial 1229 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:52:36,879] Trial 1230 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:52:37,659] Trial 1231 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:40,224] Trial 1232 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:52:41,427] Trial 1233 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:52:42,490] Trial 1234 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:52:43,279] Trial 1235 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:52:46,171] Trial 1236 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:53:05,500] Trial 1237 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 15:53:06,061] Trial 1238 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:53:06,600] Trial 1239 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:53:07,381] Trial 1240 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:53:07,956] Trial 1241 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:53:09,044] Trial 1242 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:53:11,121] Trial 1243 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:54:25,691] Trial 1244 finished with value: -0.7378770578670804 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 8.091788694472582e-07, 'lambda_l2': 1.689761599860356e-08, 'num_leaves': 190, 'feature_fraction': 0.14313128782893977, 'bagging_fraction': 0.9997785452280351, 'bagging_freq': 1, 'min_child_samples': 17, 'learning_rate': 0.0018602160727825877, 'max_depth': 32, 'min_split_gain': 0.17887337036557452, 'subsample': 0.5558673985586124, 'colsample_bytree': 0.5330141517003144, 'num_iterations': 846, 'max_bin': 434, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:54:26,330] Trial 1245 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:54:26,897] Trial 1246 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:28,068] Trial 1247 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:54:28,760] Trial 1248 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:54:29,299] Trial 1249 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:30,054] Trial 1250 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:54:31,465] Trial 1251 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:54:33,787] Trial 1252 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:54:34,368] Trial 1253 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:34,938] Trial 1254 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:35,524] Trial 1255 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:36,092] Trial 1256 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:36,766] Trial 1257 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:54:42,564] Trial 1258 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:54:43,861] Trial 1259 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:54:44,581] Trial 1260 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:55:55,506] Trial 1261 finished with value: -0.7333756610724497 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 4.784797957593865e-07, 'lambda_l2': 1.5037121843662868e-08, 'num_leaves': 171, 'feature_fraction': 0.1700321795438847, 'bagging_fraction': 0.9780637026989679, 'bagging_freq': 2, 'min_child_samples': 19, 'learning_rate': 0.0013618219768367172, 'max_depth': 31, 'min_split_gain': 0.14926100556599636, 'subsample': 0.5029810039609699, 'colsample_bytree': 0.5501293147210742, 'num_iterations': 866, 'max_bin': 376, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 15:55:56,046] Trial 1262 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:55:56,591] Trial 1263 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:55:57,731] Trial 1264 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:55:58,338] Trial 1265 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:55:58,872] Trial 1266 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:55:59,349] Trial 1267 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:55:59,905] Trial 1268 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:56:00,466] Trial 1269 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:56:01,024] Trial 1270 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:56:03,531] Trial 1271 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:56:04,042] Trial 1272 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:56:04,770] Trial 1273 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:56:05,473] Trial 1274 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:56:08,842] Trial 1275 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:56:10,120] Trial 1276 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 15:56:10,673] Trial 1277 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:56:11,252] Trial 1278 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:56:11,948] Trial 1279 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:57:05,257] Trial 1280 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:57:06,256] Trial 1281 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:57:08,631] Trial 1282 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:57:09,149] Trial 1283 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:57:09,945] Trial 1284 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:57:16,382] Trial 1285 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:57:22,865] Trial 1286 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:57:24,050] Trial 1287 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:57:24,756] Trial 1288 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:57:25,415] Trial 1289 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:57:26,281] Trial 1290 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:57:28,583] Trial 1291 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:57:31,420] Trial 1292 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:57:32,238] Trial 1293 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:57:32,967] Trial 1294 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:58:41,546] Trial 1295 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:58:44,171] Trial 1296 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:58:44,770] Trial 1297 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:58:45,608] Trial 1298 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:58:46,280] Trial 1299 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:58:47,085] Trial 1300 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:58:47,728] Trial 1301 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:58:48,425] Trial 1302 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:58:48,961] Trial 1303 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:59:43,007] Trial 1304 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 15:59:44,341] Trial 1305 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:59:45,196] Trial 1306 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:59:45,893] Trial 1307 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:59:48,630] Trial 1308 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 15:59:49,579] Trial 1309 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:59:50,262] Trial 1310 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:59:51,172] Trial 1311 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 15:59:51,854] Trial 1312 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:59:52,257] Trial 1313 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 15:59:58,394] Trial 1314 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 15:59:59,108] Trial 1315 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:00:01,678] Trial 1316 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:00:02,527] Trial 1317 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:00:23,202] Trial 1318 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:01:19,107] Trial 1319 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 16:01:19,987] Trial 1320 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:01:20,548] Trial 1321 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:01:21,074] Trial 1322 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:01:22,062] Trial 1323 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:01:22,718] Trial 1324 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:01:23,269] Trial 1325 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:02:43,819] Trial 1326 finished with value: -0.73326984244966 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.2840366530181625e-08, 'lambda_l2': 1.513299219977048e-08, 'num_leaves': 415, 'feature_fraction': 0.16615888952764907, 'bagging_fraction': 0.9830807672476184, 'bagging_freq': 2, 'min_child_samples': 20, 'learning_rate': 0.00052697283666416, 'max_depth': 32, 'min_split_gain': 0.07769219551691131, 'subsample': 0.5742759364981589, 'colsample_bytree': 0.567278411493146, 'num_iterations': 912, 'max_bin': 380, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:02:46,179] Trial 1327 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:02:47,255] Trial 1328 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:02:48,216] Trial 1329 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:02:49,568] Trial 1330 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:02:50,596] Trial 1331 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:02:51,541] Trial 1332 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:02:52,642] Trial 1333 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:02:53,852] Trial 1334 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:02:54,958] Trial 1335 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:02:55,947] Trial 1336 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:02:58,753] Trial 1337 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:02:59,423] Trial 1338 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:02,046] Trial 1339 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:03:03,474] Trial 1340 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:04,439] Trial 1341 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:06,368] Trial 1342 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:07,096] Trial 1343 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:07,824] Trial 1344 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:03:08,351] Trial 1345 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:09,050] Trial 1346 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:03:09,876] Trial 1347 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:11,115] Trial 1348 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:18,700] Trial 1349 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:03:19,414] Trial 1350 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:20,103] Trial 1351 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:21,317] Trial 1352 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:22,342] Trial 1353 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:03:23,181] Trial 1354 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:24,517] Trial 1355 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:25,319] Trial 1356 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:03:26,218] Trial 1357 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:26,903] Trial 1358 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:27,478] Trial 1359 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:28,499] Trial 1360 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:03:29,384] Trial 1361 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:29,930] Trial 1362 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:30,709] Trial 1363 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:31,391] Trial 1364 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:32,280] Trial 1365 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:33,139] Trial 1366 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:03:33,837] Trial 1367 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:34,443] Trial 1368 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:03:36,076] Trial 1369 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:03:37,094] Trial 1370 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:04:50,717] Trial 1371 finished with value: -0.7326386390094619 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 4.7042016277812404e-08, 'lambda_l2': 1.4344310601440167e-08, 'num_leaves': 219, 'feature_fraction': 0.13153519033694466, 'bagging_fraction': 0.9679845236402848, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.0009916763376753154, 'max_depth': 28, 'min_split_gain': 0.12351728068508906, 'subsample': 0.5832897579204404, 'colsample_bytree': 0.7461914111494508, 'num_iterations': 887, 'max_bin': 234, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:04:51,460] Trial 1372 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:04:52,450] Trial 1373 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:04:53,131] Trial 1374 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:04:53,825] Trial 1375 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:04:54,382] Trial 1376 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:04:54,839] Trial 1377 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:04:55,573] Trial 1378 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:04:57,958] Trial 1379 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:04:58,809] Trial 1380 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:04:59,404] Trial 1381 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:00,072] Trial 1382 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:00,671] Trial 1383 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:08,938] Trial 1384 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:05:09,551] Trial 1385 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:10,106] Trial 1386 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:10,746] Trial 1387 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:05:11,479] Trial 1388 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:12,087] Trial 1389 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:12,871] Trial 1390 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:05:13,419] Trial 1391 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:13,963] Trial 1392 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:14,556] Trial 1393 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:05:15,108] Trial 1394 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:15,782] Trial 1395 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:16,724] Trial 1396 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:05:17,272] Trial 1397 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:05:17,931] Trial 1398 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:11,490] Trial 1399 pruned. Trial was pruned at iteration 729.\n",
      "[I 2024-06-13 16:06:12,108] Trial 1400 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:13,194] Trial 1401 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:06:13,753] Trial 1402 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:14,526] Trial 1403 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:15,320] Trial 1404 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:16,102] Trial 1405 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:16,541] Trial 1406 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:17,170] Trial 1407 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:17,865] Trial 1408 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:18,971] Trial 1409 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:06:19,499] Trial 1410 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:20,992] Trial 1411 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:06:21,646] Trial 1412 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:22,716] Trial 1413 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:23,467] Trial 1414 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:24,210] Trial 1415 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:26,133] Trial 1416 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:06:26,949] Trial 1417 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:29,390] Trial 1418 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:06:30,014] Trial 1419 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:30,738] Trial 1420 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:31,373] Trial 1421 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:32,097] Trial 1422 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:32,778] Trial 1423 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:34,388] Trial 1424 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:06:35,569] Trial 1425 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:37,051] Trial 1426 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:06:37,877] Trial 1427 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:38,356] Trial 1428 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:39,129] Trial 1429 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:40,279] Trial 1430 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:06:41,757] Trial 1431 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:06:43,186] Trial 1432 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:44,175] Trial 1433 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:06:51,863] Trial 1434 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:06:59,835] Trial 1435 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:07:00,555] Trial 1436 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:01,291] Trial 1437 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:07:01,863] Trial 1438 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:02,426] Trial 1439 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:16,675] Trial 1440 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:07:17,312] Trial 1441 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:17,948] Trial 1442 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:18,934] Trial 1443 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:19,709] Trial 1444 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:07:20,216] Trial 1445 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:07:20,887] Trial 1446 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:21,906] Trial 1447 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:22,632] Trial 1448 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:24,656] Trial 1449 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:07:25,507] Trial 1450 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:07:27,196] Trial 1451 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:07:29,284] Trial 1452 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:07:30,341] Trial 1453 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:08:41,440] Trial 1454 finished with value: -0.7316965186634804 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.58306400859115e-07, 'lambda_l2': 0.15534702824527313, 'num_leaves': 171, 'feature_fraction': 0.13984895444787207, 'bagging_fraction': 0.952415920562127, 'bagging_freq': 2, 'min_child_samples': 20, 'learning_rate': 0.001360261896185257, 'max_depth': 33, 'min_split_gain': 0.3120038049416286, 'subsample': 0.532815529430214, 'colsample_bytree': 0.5344214910957226, 'num_iterations': 936, 'max_bin': 377, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:08:42,558] Trial 1455 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:08:43,146] Trial 1456 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:08:43,886] Trial 1457 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:08:44,458] Trial 1458 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:08:45,124] Trial 1459 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:08:45,853] Trial 1460 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:08:46,574] Trial 1461 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:05,425] Trial 1462 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:09:06,094] Trial 1463 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:06,785] Trial 1464 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:07,508] Trial 1465 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:08,060] Trial 1466 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:26,567] Trial 1467 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:09:27,169] Trial 1468 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:28,235] Trial 1469 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:09:28,796] Trial 1470 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:29,331] Trial 1471 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:31,779] Trial 1472 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:09:32,533] Trial 1473 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:33,692] Trial 1474 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:09:40,906] Trial 1475 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:09:41,369] Trial 1476 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:42,039] Trial 1477 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:42,670] Trial 1478 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:44,051] Trial 1479 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:09:45,191] Trial 1480 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:45,951] Trial 1481 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:46,656] Trial 1482 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:47,468] Trial 1483 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:48,031] Trial 1484 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:48,581] Trial 1485 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:49,154] Trial 1486 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:49,844] Trial 1487 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:52,420] Trial 1488 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:09:53,084] Trial 1489 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:53,971] Trial 1490 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:55,144] Trial 1491 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:09:56,043] Trial 1492 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:58,560] Trial 1493 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:09:59,252] Trial 1494 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:09:59,984] Trial 1495 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:00,820] Trial 1496 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:01,657] Trial 1497 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:03,822] Trial 1498 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:10:06,866] Trial 1499 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:10:07,760] Trial 1500 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:10,821] Trial 1501 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:10:12,148] Trial 1502 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:13,343] Trial 1503 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:14,685] Trial 1504 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:15,944] Trial 1505 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:16,572] Trial 1506 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:17,307] Trial 1507 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:19,578] Trial 1508 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:10:20,818] Trial 1509 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:21,414] Trial 1510 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:22,226] Trial 1511 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:23,166] Trial 1512 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:23,662] Trial 1513 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:24,248] Trial 1514 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:24,970] Trial 1515 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:25,892] Trial 1516 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:26,917] Trial 1517 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:27,652] Trial 1518 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:28,533] Trial 1519 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:31,330] Trial 1520 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:10:32,368] Trial 1521 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:32,980] Trial 1522 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:33,835] Trial 1523 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:34,521] Trial 1524 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:35,867] Trial 1525 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:10:45,213] Trial 1526 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:10:46,221] Trial 1527 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:47,034] Trial 1528 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:48,085] Trial 1529 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:50,538] Trial 1530 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:10:51,186] Trial 1531 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:51,991] Trial 1532 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:52,851] Trial 1533 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:53,610] Trial 1534 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:54,516] Trial 1535 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:10:55,505] Trial 1536 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:56,400] Trial 1537 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:10:56,929] Trial 1538 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:11:28,424] Trial 1539 finished with value: -0.7334992835988949 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 8.311803745368029e-08, 'lambda_l2': 0.9012087471814559, 'num_leaves': 432, 'feature_fraction': 0.14221321349886742, 'bagging_fraction': 0.9989233637924554, 'bagging_freq': 2, 'min_child_samples': 21, 'learning_rate': 0.00044779213512394185, 'max_depth': 26, 'min_split_gain': 0.14354635606973176, 'subsample': 0.5829300516120464, 'colsample_bytree': 0.7612906216986126, 'num_iterations': 370, 'max_bin': 339, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:11:54,425] Trial 1540 finished with value: -0.7176425549394525 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.1344541293235423e-07, 'lambda_l2': 1.2737812531615884, 'num_leaves': 438, 'feature_fraction': 0.12838228097834856, 'bagging_fraction': 0.9986791257326814, 'bagging_freq': 2, 'min_child_samples': 27, 'learning_rate': 0.00033451329409043813, 'max_depth': 27, 'min_split_gain': 0.12182492778812545, 'subsample': 0.5565666700103129, 'colsample_bytree': 0.7705659707150855, 'num_iterations': 377, 'max_bin': 321, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:12:12,298] Trial 1541 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:12:13,653] Trial 1542 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:12:14,224] Trial 1543 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:12:16,486] Trial 1544 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:12:19,433] Trial 1545 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:12:45,023] Trial 1546 finished with value: -0.7323774559689442 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 9.070174983398927e-08, 'lambda_l2': 0.004668079515763525, 'num_leaves': 185, 'feature_fraction': 0.13982555941486965, 'bagging_fraction': 0.9994686035263045, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.00047739522210580915, 'max_depth': 26, 'min_split_gain': 0.13039183961104406, 'subsample': 0.5759832695879608, 'colsample_bytree': 0.806600025669002, 'num_iterations': 278, 'max_bin': 298, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:12:47,627] Trial 1547 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:12:48,317] Trial 1548 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:12:48,992] Trial 1549 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:12:49,665] Trial 1550 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:12:55,994] Trial 1551 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:12:56,726] Trial 1552 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:12:57,447] Trial 1553 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:12:59,802] Trial 1554 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:13:00,446] Trial 1555 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:13:01,718] Trial 1556 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:13:02,368] Trial 1557 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:13:25,872] Trial 1558 finished with value: -0.730848130511148 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 2.3901682072083693e-07, 'lambda_l2': 0.011062589670023167, 'num_leaves': 207, 'feature_fraction': 0.13115704181352755, 'bagging_fraction': 0.9999868273869833, 'bagging_freq': 1, 'min_child_samples': 22, 'learning_rate': 0.0004502312049623144, 'max_depth': 25, 'min_split_gain': 0.12510713197175438, 'subsample': 0.5802505860720447, 'colsample_bytree': 0.8070294626322378, 'num_iterations': 276, 'max_bin': 330, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:13:29,522] Trial 1559 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:13:30,127] Trial 1560 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:13:30,740] Trial 1561 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:13:31,410] Trial 1562 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:13:32,125] Trial 1563 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:14:02,010] Trial 1564 finished with value: -0.727870889512827 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 3.252036016027948e-07, 'lambda_l2': 0.05244420295607373, 'num_leaves': 206, 'feature_fraction': 0.100298852731771, 'bagging_fraction': 0.9843758346751692, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.0004533004582643313, 'max_depth': 24, 'min_split_gain': 0.08371597784084825, 'subsample': 0.5904806265536003, 'colsample_bytree': 0.8683653851484161, 'num_iterations': 380, 'max_bin': 332, 'seed': 1338}. Best is trial 1104 with value: -0.7398982304741816.\n",
      "[I 2024-06-13 16:14:04,773] Trial 1565 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:14:05,512] Trial 1566 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:12,653] Trial 1567 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:14:13,831] Trial 1568 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:14:14,606] Trial 1569 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:17,439] Trial 1570 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:14:18,237] Trial 1571 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:14:18,813] Trial 1572 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:19,325] Trial 1573 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:14:22,201] Trial 1574 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:14:23,131] Trial 1575 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:24,116] Trial 1576 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:24,830] Trial 1577 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:36,049] Trial 1578 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:14:37,111] Trial 1579 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:14:44,689] Trial 1580 finished with value: -0.7661984153621627 and parameters: {'objective': 'regression_l2', 'boosting_type': 'gbdt', 'linear_tree': True, 'lambda_l1': 7.646724716569628e-08, 'lambda_l2': 1.1628288287984516, 'num_leaves': 172, 'feature_fraction': 0.14446333893334853, 'bagging_fraction': 0.9694704018889345, 'bagging_freq': 1, 'min_child_samples': 24, 'learning_rate': 0.0376454335840857, 'max_depth': 28, 'min_split_gain': 0.14232664081571772, 'subsample': 0.7076405862385893, 'colsample_bytree': 0.4420944624129144, 'num_iterations': 873, 'max_bin': 372, 'seed': 1338}. Best is trial 1580 with value: -0.7661984153621627.\n",
      "[I 2024-06-13 16:14:45,461] Trial 1581 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:14:45,990] Trial 1582 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:46,452] Trial 1583 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:47,118] Trial 1584 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:47,800] Trial 1585 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:48,344] Trial 1586 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:49,590] Trial 1587 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:14:50,399] Trial 1588 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:14:55,831] Trial 1589 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:14:57,109] Trial 1590 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:14:58,529] Trial 1591 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:14:59,137] Trial 1592 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:14:59,765] Trial 1593 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:00,381] Trial 1594 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:01,124] Trial 1595 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:04,592] Trial 1596 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:15:05,307] Trial 1597 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:05,940] Trial 1598 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:06,695] Trial 1599 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:07,365] Trial 1600 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:08,105] Trial 1601 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:08,960] Trial 1602 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:11,873] Trial 1603 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:15:12,589] Trial 1604 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:13,206] Trial 1605 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:13,891] Trial 1606 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:14,813] Trial 1607 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:15,617] Trial 1608 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:16,426] Trial 1609 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:17,431] Trial 1610 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:18,078] Trial 1611 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:18,604] Trial 1612 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:19,200] Trial 1613 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:19,873] Trial 1614 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:20,532] Trial 1615 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:21,126] Trial 1616 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:21,872] Trial 1617 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:22,501] Trial 1618 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:23,269] Trial 1619 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:23,810] Trial 1620 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:24,422] Trial 1621 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:24,992] Trial 1622 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:25,606] Trial 1623 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:26,967] Trial 1624 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:15:27,636] Trial 1625 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:36,987] Trial 1626 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:15:37,611] Trial 1627 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:38,499] Trial 1628 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:39,321] Trial 1629 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:39,921] Trial 1630 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:40,633] Trial 1631 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:41,270] Trial 1632 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:41,747] Trial 1633 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:15:42,417] Trial 1634 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:43,081] Trial 1635 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:44,129] Trial 1636 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:44,883] Trial 1637 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:15:53,666] Trial 1638 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:15:54,262] Trial 1639 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:16:31,185] Trial 1640 finished with value: -0.7350641175927902 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 6.425776762313392e-08, 'lambda_l2': 1.2586723273507225, 'num_leaves': 181, 'feature_fraction': 0.13525084885883087, 'bagging_fraction': 0.999840115795986, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.0007440730826575916, 'max_depth': 30, 'min_split_gain': 0.19474726236704507, 'subsample': 0.8006821903153785, 'colsample_bytree': 0.8530259148656211, 'num_iterations': 408, 'max_bin': 370, 'seed': 1338}. Best is trial 1580 with value: -0.7661984153621627.\n",
      "[I 2024-06-13 16:16:34,202] Trial 1641 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:16:34,853] Trial 1642 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:16:35,618] Trial 1643 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:16:36,241] Trial 1644 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:16:36,884] Trial 1645 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:16:39,924] Trial 1646 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:16:50,455] Trial 1647 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:16:58,049] Trial 1648 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:16:58,685] Trial 1649 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:17:00,100] Trial 1650 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:17:00,778] Trial 1651 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:17:01,371] Trial 1652 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:17:02,252] Trial 1653 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:17:02,850] Trial 1654 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:17:26,396] Trial 1655 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:17:26,997] Trial 1656 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:17:27,596] Trial 1657 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:17:28,209] Trial 1658 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:17:30,744] Trial 1659 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:17:38,330] Trial 1660 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:17:39,730] Trial 1661 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:17:40,227] Trial 1662 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:01,306] Trial 1663 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:18:24,263] Trial 1664 pruned. Trial was pruned at iteration 243.\n",
      "[I 2024-06-13 16:18:25,045] Trial 1665 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:18:25,974] Trial 1666 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:18:26,596] Trial 1667 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:27,762] Trial 1668 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:18:34,918] Trial 1669 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:18:35,629] Trial 1670 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:36,239] Trial 1671 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:37,463] Trial 1672 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:18:38,096] Trial 1673 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:46,112] Trial 1674 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:18:47,749] Trial 1675 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:18:48,964] Trial 1676 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:18:49,598] Trial 1677 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:50,410] Trial 1678 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:18:51,257] Trial 1679 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:18:53,762] Trial 1680 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:18:54,485] Trial 1681 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:55,141] Trial 1682 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:55,693] Trial 1683 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:56,675] Trial 1684 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:18:57,290] Trial 1685 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:57,914] Trial 1686 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:58,568] Trial 1687 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:18:59,258] Trial 1688 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:00,396] Trial 1689 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:07,550] Trial 1690 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:19:08,567] Trial 1691 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:19:09,383] Trial 1692 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:10,041] Trial 1693 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:10,952] Trial 1694 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:11,636] Trial 1695 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:12,240] Trial 1696 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:13,674] Trial 1697 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:19:14,316] Trial 1698 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:16,394] Trial 1699 pruned. Trial was pruned at iteration 27.\n",
      "[I 2024-06-13 16:19:17,134] Trial 1700 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:18,795] Trial 1701 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:19:19,579] Trial 1702 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:20,154] Trial 1703 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:21,468] Trial 1704 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:22,215] Trial 1705 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:22,908] Trial 1706 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:23,919] Trial 1707 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:25,202] Trial 1708 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:19:25,822] Trial 1709 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:26,519] Trial 1710 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:27,329] Trial 1711 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:28,409] Trial 1712 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:29,067] Trial 1713 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:29,914] Trial 1714 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:30,571] Trial 1715 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:31,126] Trial 1716 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:38,206] Trial 1717 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:19:39,412] Trial 1718 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-13 16:19:46,825] Trial 1719 pruned. Trial was pruned at iteration 81.\n",
      "[I 2024-06-13 16:19:47,544] Trial 1720 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:48,386] Trial 1721 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:49,038] Trial 1722 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:19:49,750] Trial 1723 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-06-13 16:19:50,463] Trial 1724 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-06-13 16:20:19,836] Trial 1725 finished with value: -0.7358696417455267 and parameters: {'objective': 'regression_l2', 'boosting_type': 'rf', 'linear_tree': True, 'lambda_l1': 1.9932218947228327e-07, 'lambda_l2': 9.176028570960118e-07, 'num_leaves': 201, 'feature_fraction': 0.12904113610600257, 'bagging_fraction': 0.9690910950701977, 'bagging_freq': 1, 'min_child_samples': 20, 'learning_rate': 0.00038169484172485255, 'max_depth': 33, 'min_split_gain': 0.10022491875213116, 'subsample': 0.6560117021750806, 'colsample_bytree': 0.7777094754027791, 'num_iterations': 326, 'max_bin': 340, 'seed': 1338}. Best is trial 1580 with value: -0.7661984153621627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'objective': 'regression_l2', 'boosting_type': 'gbdt', 'linear_tree': True, 'lambda_l1': 7.646724716569628e-08, 'lambda_l2': 1.1628288287984516, 'num_leaves': 172, 'feature_fraction': 0.14446333893334853, 'bagging_fraction': 0.9694704018889345, 'bagging_freq': 1, 'min_child_samples': 24, 'learning_rate': 0.0376454335840857, 'max_depth': 28, 'min_split_gain': 0.14232664081571772, 'subsample': 0.7076405862385893, 'colsample_bytree': 0.4420944624129144, 'num_iterations': 873, 'max_bin': 372, 'seed': 1338}\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function\n",
    "def objective(trial):\n",
    "\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)\n",
    "\n",
    "    param = {\n",
    "        'objective': trial.suggest_categorical(\"objective\", [\"regression_l2\", \"regression_l1\"]),\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': trial.suggest_categorical(\"boosting_type\", [\"gbdt\", \"rf\", \"dart\"]),\n",
    "        'linear_tree': trial.suggest_categorical(\"linear_tree\", [True, False]),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 50),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'num_iterations': trial.suggest_int('num_iterations', 100, 1000),\n",
    "        'max_bin': trial.suggest_int(\"max_bin\", 64, 1024),\n",
    "        'seed': trial.suggest_categorical(\"seed\", [SEED]),\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmse')\n",
    "\n",
    "    param_deep = copy.deepcopy(param)\n",
    "    del param_deep[\"num_iterations\"]\n",
    "    gbm = lgb.train(param_deep, \n",
    "                    dtrain, \n",
    "                    num_boost_round=param[\"num_iterations\"], \n",
    "                    valid_sets=[dvalid], \n",
    "                    callbacks=[pruning_callback])\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    r2 = r2_score(valid_y, preds)\n",
    "    \n",
    "    return -r2\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "\n",
    "sampler = TPESampler(seed=SEED) # Make the sampler behave in a deterministic way.\n",
    "#sampler = RandomSampler(seed=SEED)\n",
    "\n",
    "#pruner = optuna.pruners.MedianPruner()\n",
    "pruner = optuna.pruners.HyperbandPruner()\n",
    "\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner, sampler=sampler)\n",
    "study.optimize(objective, n_trials=20000, timeout=7200) # run for 2 hours\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print('Best hyperparameters: ', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression_l2',\n",
       " 'boosting_type': 'gbdt',\n",
       " 'linear_tree': True,\n",
       " 'lambda_l1': 7.646724716569628e-08,\n",
       " 'lambda_l2': 1.1628288287984516,\n",
       " 'num_leaves': 172,\n",
       " 'feature_fraction': 0.14446333893334853,\n",
       " 'bagging_fraction': 0.9694704018889345,\n",
       " 'bagging_freq': 1,\n",
       " 'min_child_samples': 24,\n",
       " 'learning_rate': 0.0376454335840857,\n",
       " 'max_depth': 28,\n",
       " 'min_split_gain': 0.14232664081571772,\n",
       " 'subsample': 0.7076405862385893,\n",
       " 'colsample_bytree': 0.4420944624129144,\n",
       " 'num_iterations': 873,\n",
       " 'max_bin': 372,\n",
       " 'seed': 1338}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goncaloabreu/repos/fusionchallenge/virtual/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9694704018889345, subsample=0.7076405862385893 will be ignored. Current value: bagging_fraction=0.9694704018889345\n",
      "[LightGBM] [Warning] feature_fraction is set=0.14446333893334853, colsample_bytree=0.4420944624129144 will be ignored. Current value: feature_fraction=0.14446333893334853\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9694704018889345, subsample=0.7076405862385893 will be ignored. Current value: bagging_fraction=0.9694704018889345\n",
      "[LightGBM] [Warning] feature_fraction is set=0.14446333893334853, colsample_bytree=0.4420944624129144 will be ignored. Current value: feature_fraction=0.14446333893334853\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 252588\n",
      "[LightGBM] [Info] Number of data points in the train set: 5196, number of used features: 679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9694704018889345, subsample=0.7076405862385893 will be ignored. Current value: bagging_fraction=0.9694704018889345\n",
      "[LightGBM] [Warning] feature_fraction is set=0.14446333893334853, colsample_bytree=0.4420944624129144 will be ignored. Current value: feature_fraction=0.14446333893334853\n",
      "[LightGBM] [Info] Start training from score 1.897370\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "dvalid = lgb.Dataset(valid_x, label=valid_y, reference=dtrain)    \n",
    "\n",
    "gbm = lgb.train(study.best_params, dtrain, valid_sets=[dvalid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2978621756535022"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gbm.predict(valid_x)\n",
    "rmse = root_mean_squared_error(valid_y, preds)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Nonlinear GX turbulence calculations, linear regression using cvdrift: $R^2$ = 0.766')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R2 = r2_score(valid_y, preds)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(valid_y, preds, '.')\n",
    "plt.plot([-2, 4], [-2, 4], ':k')\n",
    "plt.xlabel(\"Actual log(Q) from GX\")\n",
    "plt.ylabel(\"Predicted log(Q)\")\n",
    "plt.title(f\"Nonlinear GX turbulence calculations, linear regression using cvdrift: $R^2$ = {R2:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the number of top features to plot\n",
    "top_n_features = 20  # Change this value to display more or fewer features\n",
    "\n",
    "# Plot feature importance using Gain\n",
    "ax = lgb.plot_importance(gbm, importance_type=\"gain\", max_num_features=top_n_features, figsize=(10, 8))\n",
    "ax.set_title(\"LightGBM Feature Importance (Gain)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study.best_params[\"linear_tree\"] == False:\n",
    "    explainer = shap.TreeExplainer(gbm)\n",
    "    shap_values = explainer(features)\n",
    "    shap.summary_plot(shap_values, features, max_display=top_n_features)\n",
    "else:\n",
    "    print(\"SHAP does not work with linear trees\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
